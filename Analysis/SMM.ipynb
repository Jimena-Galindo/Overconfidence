{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dgp\n",
    "# matrices: matrix[0] is the low type, matrix[2] is the high type. column 0 is low omega, row 0 is low effort\n",
    "ml = np.array([[.20, .25, .40], [.07, .30, .45], [.02, .20, .50]])\n",
    "mm = np.array([[.40, .45, .65], [.30, .65, .69], [.05, .50, .80]])\n",
    "mh = np.array([[.45, .55, .75], [.35, .69, .80], [.25, .65, .98]])\n",
    "\n",
    "msc = [ml, mm, mh]\n",
    "\n",
    "# number of periods\n",
    "T = 11\n",
    "\n",
    "# number of trials\n",
    "be_trials = 10\n",
    "\n",
    "seed = 3452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the priors, simulate the choices under each of the parameterizations of the bias from attributions\n",
    "# where the attribution is [c_positive, c_negative, c_negative, c_positive] for each of the possible \n",
    "# combinations of c_positive and c_negative\n",
    "\n",
    "# create a matrix of the possible combinations of c_positive and c_negative\n",
    "c_H = np.array([x for x in range(10, 200, 10)])/100\n",
    "c_M = np.array([x for x in range(10, 200, 10)])/100\n",
    "c_L = np.array([x for x in range(10, 200, 10)])/100\n",
    "\n",
    "grid_good_HML = np.array(np.meshgrid(c_H, c_M, c_L)).T.reshape(-1, 3)\n",
    "\n",
    "# turn into a dataframe\n",
    "grid_good_HML = pd.DataFrame(grid_good_HML, columns = ['c_H', 'c_M', 'c_L'])\n",
    "\n",
    "# keep only values for which c_H < c_M < c_L\n",
    "grid_good_HML = grid_good_HML[grid_good_HML['c_H'] < grid_good_HML['c_M']]\n",
    "grid_good_HML = grid_good_HML[grid_good_HML['c_M'] < grid_good_HML['c_L']]\n",
    "\n",
    "#turn back into an array\n",
    "grid_good_HML = np.array(grid_good_HML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list of possible prior beliefs on theta\n",
    "priors_theta = [[1/3, 1/3, 1/3], \n",
    "                [1/2, 1/4, 1/4],\n",
    "                [3/4, 1/8, 1/8],\n",
    "                [9/10, 1/20, 1/20],\n",
    "                [1/4, 1/2, 1/4],\n",
    "                [1/8, 3/4, 1/8],\n",
    "                [1/20, 9/10, 1/20],\n",
    "                [1/4, 1/4, 1/2],\n",
    "                [1/8, 1/8, 3/4],\n",
    "                [1/20, 1/20, 9/10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prior on omega is induced and uniform\n",
    "prior_omega = [1/3, 1/3, 1/3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### THIS IS THE BAYES UPDATE WITH THE BIAS PARAMETERS C######\n",
    "# joint bayesian update\n",
    "\n",
    "def joint_bayes_biased(p0, signal, M, e_index, c):\n",
    "    # c should be [c_H, c_M, c_L]\n",
    "\n",
    "    # number of sucesses\n",
    "    k = sum(signal)\n",
    "    n = len(signal)\n",
    "    # determine if it is good news or bad news and set the parameter c accordingly\n",
    "    if k>=n/2:\n",
    "        c_H = c[0]\n",
    "        c_M = c[1]\n",
    "        c_L = c[2]\n",
    "    else:\n",
    "        c_L = c[2]\n",
    "        c_M = c[1]\n",
    "        c_H = c[0]\n",
    "    \n",
    "    # the probabilities of having observed each of the signals\n",
    "    matrix = np.array([sp.stats.binom.pmf(k, n, M[0][e_index, :], loc=0), \n",
    "                       sp.stats.binom.pmf(k, n, M[1][e_index, :], loc=0), \n",
    "                       sp.stats.binom.pmf(k, n, M[2][e_index, :], loc=0)])\n",
    "    \n",
    "    \n",
    "    if k>=n/2:\n",
    "        matrix_bias = [[matrix[0, 0]**c_L, matrix[0, 1]**c_L, matrix[0, 2]**c_L],\n",
    "                       [matrix[1, 0]**c_M, matrix[1, 1]**c_M, matrix[1, 2]**c_M],\n",
    "                       [matrix[2, 0]**c_H, matrix[2, 1]**c_H, matrix[2, 2]**c_H]]\n",
    "    else:\n",
    "        matrix_bias = [[matrix[0, 0]**c_L, matrix[0, 1]**c_M, matrix[0, 2]**c_H],\n",
    "                       [matrix[1, 0]**c_L, matrix[1, 1]**c_M, matrix[1, 2]**c_H],\n",
    "                       [matrix[2, 0]**c_L, matrix[2, 1]**c_M, matrix[2, 2]**c_H]]\n",
    "    \n",
    "    # set the numerators\n",
    "    num = np.diagflat(p0) @ np.diagflat(matrix_bias)\n",
    "    #take only the diagonal\n",
    "    num = np.diag(num)\n",
    "\n",
    "    # sum all the numerators to get the denominator\n",
    "    denom = np.sum(num)\n",
    "\n",
    "    # the posterior beliefs are each of the numerators divided by the denominator\n",
    "    p1 = num/denom\n",
    "\n",
    "    # p1 has the order (00, 01, 02, 10, 11, 12, 20, 21, 22)\n",
    "    \n",
    "    return p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian choices (the inputs are the belief (nine-dimensional array) and the DGP (msc), returns the index of the choice that maximizes the expected utility)\n",
    "# this can be used for the unbiased and the biased updates since it only takes the posterior belief ans calculates the expectated utility for each of the choices\n",
    "\n",
    "def joint_bayes_c(p1, M):\n",
    "    # compute the expected payoffs for each of the 3 choices\n",
    "    # the expected payoff is the probability of success times the probability of that combination of parameters\n",
    "    # Take the first row of each of the matrices in M and cancatenate them (this will match the order of the probabilities in the posterior)\n",
    "    choices_1 = np.concatenate((M[0][0, :], M[1][0, :], M[2][0, :]))\n",
    "    # Take the second row of each of the matrices in M and stack them\n",
    "    choices_2 = np.concatenate((M[0][1, :], M[1][1, :], M[2][1, :]))\n",
    "    # Take the third row of each of the matrices in M and concatenate them\n",
    "    choices_3 = np.concatenate((M[0][2, :], M[1][2, :], M[2][2, :]))\n",
    "\n",
    "    # multiply the choices by the probabilities in the posterior\n",
    "    Eu= [choices_1@p1, choices_2@p1, choices_3@p1]\n",
    "\n",
    "    e_index = np.argmax(Eu)\n",
    "    \n",
    "    return e_index\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that simulates the joint biased bayes only (this can be turned into the correct bayesian y settinc c=[1, 1, 1, 1])\n",
    "\n",
    "def simulate_joint_bayes_biased(theta, omega, p0_theta, p0_omega, M, c, T, trials, seed, epsilon):\n",
    "    \n",
    "    ###### Determine the outcomes beforehand\n",
    "    # set a seed for each type\n",
    "    rng_H = np.random.default_rng(seed=seed)\n",
    "    \n",
    "    \n",
    "\n",
    "    #############\n",
    "    # generate all the draws for T periods for each type and for each effort choice\n",
    "    ############\n",
    "\n",
    "    ##### for the high types\n",
    "    # outcomes after choosing L\n",
    "    outcome_H_L = rng_H.binomial(1, M[2][0, omega], size=(T, trials))\n",
    "    # outcomes after choosing M\n",
    "    outcome_H_M = rng_H.binomial(1, M[2][1, omega], size=(T, trials))\n",
    "    # outcomes after choosing H\n",
    "    outcome_H_H = rng_H.binomial(1, M[2][2, omega], size=(T, trials))\n",
    "\n",
    "    ##### for the medium types\n",
    "    rng_M = np.random.default_rng(seed=seed)\n",
    "    # after low effort\n",
    "    outcome_M_L = rng_M.binomial(1, M[1][0, omega], size=(T, trials))\n",
    "    # after medium effort\n",
    "    outcome_M_M = rng_M.binomial(1, M[1][1, omega], size=(T, trials))\n",
    "    # after high effort\n",
    "    outcome_M_H = rng_M.binomial(1, M[1][2, omega], size=(T, trials))\n",
    "\n",
    "    #### for the low types\n",
    "    rng_L = np.random.default_rng(seed=seed)\n",
    "    outcomes_L_L = rng_L.binomial(1, M[0][0, omega], size=(T, trials))\n",
    "    outcomes_L_M = rng_L.binomial(1, M[0][1, omega], size=(T, trials))\n",
    "    outcomes_L_H = rng_L.binomial(1, M[0][2, omega], size=(T, trials))\n",
    "\n",
    "    # stack the outcome vectors foe each type into a matrix. first element is the effort choice, secod is t\n",
    "    outcomes_H = np.stack((outcome_H_L, outcome_H_M, outcome_H_H))\n",
    "    outcomes_M = np.stack((outcome_M_L, outcome_M_M, outcome_M_H))\n",
    "    outcomes_L = np.stack((outcomes_L_L, outcomes_L_M, outcomes_L_H))\n",
    "\n",
    "    # stack all the matrices into a single outcomes matrix of matrices\n",
    "    outcomes = np.stack((outcomes_L, outcomes_M, outcomes_H))\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    # set empty vectors where all the data will be saved period by period for each of the models\n",
    "    ############\n",
    "    # beliefs\n",
    "    # take every value of p0_theta and multiply by each value of p0_omega\n",
    "    p_joint_bayes_biased = [np.kron(p0_theta, p0_omega)]\n",
    "    \n",
    "    # choices\n",
    "    e_joint_bay_biased = [joint_bayes_c(p_joint_bayes_biased[0], M)]\n",
    "    signal = [0]\n",
    "    \n",
    "    signals = outcomes[theta]\n",
    "    \n",
    "    for t in range(T):\n",
    "        # get the signals \n",
    "        \n",
    "        signal_bay = signals[e_joint_bay_biased[t], t]\n",
    "        signal.append(sum(signal_bay))\n",
    "        \n",
    "        # update beliefs \n",
    "        \n",
    "        p1_joint = joint_bayes_biased(p_joint_bayes_biased[t], signal_bay, M, e_joint_bay_biased[t], c)\n",
    "        p_joint_bayes_biased.append(p1_joint)\n",
    "    \n",
    "        \n",
    "        # Choices\n",
    "\n",
    "        # draw a random number between 0 and 1 to determine if the agent will tremble or not\n",
    "        tremble = np.random.uniform(0, 1)\n",
    "        # if the agent trembles, then choose a random effort level\n",
    "        if tremble<epsilon:\n",
    "            e_joint_biased_t = np.random.randint(0, 3)\n",
    "        else:\n",
    "        # if the agent does not tremble, then choose the effort level that maximizes the expected utility\n",
    "            e_joint_biased_t = joint_bayes_c(p_joint_bayes_biased[t], M)\n",
    "        \n",
    "        e_joint_bay_biased.append(e_joint_biased_t)\n",
    "        \n",
    "    return e_joint_bay_biased, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the observed data\n",
    "updates = pd.read_csv('../Clean/updates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tremble in choices\n",
    "round1 = updates[updates['round_number']==1]\n",
    "epsilon = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior distribution\n",
    "prior = updates.groupby(['belief', 'certainty']).size().reset_index(name='counts')\n",
    "prior['prob'] = prior['counts']/prior['counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the probability of each type\n",
    "parametrizations = updates.groupby(['type', 'rate'])['code'].count().reset_index(name='counts')\n",
    "parametrizations['prob'] = parametrizations['counts']/parametrizations['counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that maps each pair of belief and certainty to the prior on theta\n",
    "def prior_map(belief, certainty):\n",
    "    if belief == 0:\n",
    "        if certainty==100:\n",
    "            p0 = [9/10, 1/20, 1/20]\n",
    "        elif certainty==75:\n",
    "            p0 = [3/4, 1/8, 1/8]\n",
    "        elif certainty==50:\n",
    "            p0 = [1/2, 1/4, 1/4]\n",
    "        else:\n",
    "            p0 = [1/3, 1/3, 1/3]\n",
    "    elif belief == 1:\n",
    "        if certainty==100:\n",
    "            p0 = [1/20, 9/10, 1/20]\n",
    "        elif certainty==75:\n",
    "            p0 = [1/8, 3/4, 1/8]\n",
    "        elif certainty==50:\n",
    "            p0 = [1/4, 1/2, 1/4]\n",
    "        else:\n",
    "            p0 = [1/3, 1/3, 1/3]\n",
    "    elif belief == 2:\n",
    "        if certainty==100:\n",
    "            p0 = [1/20, 1/20, 9/10]\n",
    "        elif certainty==75:\n",
    "            p0 = [1/8, 1/8, 3/4]\n",
    "        elif certainty==50:\n",
    "            p0 = [1/4, 1/4, 1/2]\n",
    "        else:\n",
    "            p0 = [1/3, 1/3, 1/3]\n",
    "    else:\n",
    "        p0 = [1/3, 1/3, 1/3]\n",
    "    \n",
    "    return p0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each possible set of parameters in the grid, simulate the data for multiple agents\n",
    "#\n",
    "# start a list where all the dataframes will be saved\n",
    "sim_all = []\n",
    "#pd.DataFrame(columns=['round', 'effort', 'theta', 'omega', 'c_H', 'c_M', 'c_L', 'ind', 'signal'])\n",
    "\n",
    "for i in range(len(grid_good_HML)):\n",
    "    c = grid_good_HML[i]\n",
    "    # parameter level data\n",
    "    simulation_c= pd.DataFrame(columns=['round', 'effort', 'theta', 'omega', 'c_H', 'c_M', 'c_L', 'ind', 'signal'])\n",
    "    N=100\n",
    "    # simulate a sample of N agents. \n",
    "    for i in range(N):\n",
    "        # For each agent draw a type from the distribution of parametrizations\n",
    "        # draw an integer from 0 to 8 where the probability of each integer is given by the column prob in parametrizations\n",
    "        # this will be the index of the row in parametrizations that will be chosen\n",
    "        # the row will have the type and the rate of the agent\n",
    "        theta_index = np.random.choice(9, p=parametrizations['prob'])\n",
    "        # get the type and the rate\n",
    "        theta = parametrizations['type'][theta_index]\n",
    "        omega = parametrizations['rate'][theta_index]\n",
    "\n",
    "        # For each agent draw a prior from the distribution of priors\n",
    "        # draw an integer from 0 to 12 where the probability of each integer is given by the column prob in prior\n",
    "        # this will be the index of the row in prior that will be chosen\n",
    "        # the row will have the prior on theta and the certainty of the agent\n",
    "        prior_index = np.random.choice(13, p=prior['prob'])\n",
    "        # get the belief and the certainty\n",
    "        belief = prior['belief'][prior_index]\n",
    "        certainty = prior['certainty'][prior_index]\n",
    "\n",
    "        # map the belief and the certainty to the prior on theta\n",
    "        p0_theta = prior_map(belief, certainty)\n",
    "\n",
    "        # set the round_numbers\n",
    "        rounds = [t+1 for t in range(T+1)]\n",
    "\n",
    "        #individual level data\n",
    "        simulation_i = pd.DataFrame(columns=['round', 'effort', 'theta', 'omega', 'c_H', 'c_M', 'c_L'])\n",
    "        \n",
    "        e, s= simulate_joint_bayes_biased(theta, omega, p0_theta, prior_omega, msc, c, T, be_trials, seed, epsilon)\n",
    "\n",
    "        simulation_i['round'] = rounds\n",
    "        simulation_i['theta'] = theta\n",
    "        simulation_i['omega'] = omega\n",
    "        simulation_i['effort'] = e\n",
    "        simulation_i['signal'] = s\n",
    "        simulation_i['ind'] = str(i)+ str(c)\n",
    "        simulation_i['belief'] = belief\n",
    "        simulation_i['certainty'] = certainty\n",
    "\n",
    "        # append to the dataframe for the parameters\n",
    "        simulation_c=simulation_c.append(simulation_i)\n",
    "        \n",
    "    # add columns with the parameters of the simulation\n",
    "    simulation_c['c_H'] = c[0]\n",
    "    simulation_c['c_M'] = c[1]\n",
    "    simulation_c['c_L'] = c[2]\n",
    "\n",
    "    # return a list of dataframes. One for each set of parameters in the grid\n",
    "    sim_all.append(simulation_c)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with the index of the parameterization to each dataframe\n",
    "for i in range(len(sim_all)):\n",
    "    sim_all[i]['parametrization'] = i  \n",
    "\n",
    "# stack all the elements of the list into a single dataframe\n",
    "sim_all = pd.concat(sim_all)\n",
    "\n",
    "# save the data\n",
    "sim_all.to_csv('simulations_smm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "sim_all = pd.read_csv('simulations_smm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows in which signal is nan\n",
    "sim_all = sim_all.dropna(subset=['signal'])\n",
    "# change signal_previous to integer\n",
    "sim_all['signal'] = sim_all['signal'].astype(int)\n",
    "# change parametrization to integer\n",
    "sim_all['parametrization'] = sim_all['parametrization'].astype(int)\n",
    "# change round to integer\n",
    "sim_all['round'] = sim_all['round'].astype(int)\n",
    "# change effort to integer\n",
    "sim_all['effort'] = sim_all['effort'].astype(int)\n",
    "# change theta to integer\n",
    "sim_all['theta'] = sim_all['theta'].astype(int)\n",
    "# change omega to integer\n",
    "sim_all['omega'] = sim_all['omega'].astype(int)\n",
    "# change belief to integer\n",
    "sim_all['belief'] = sim_all['belief'].astype(int)\n",
    "# change certainty to integer\n",
    "sim_all['certainty'] = sim_all['certainty'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each possible parametrization, estimate the moments: regression parameters for the reaction to good news and bad news\n",
    "\n",
    "# add a column called news_previous that is the value of the signal in the previous period\n",
    "sim_all['signal_previous'] = sim_all.groupby(['ind'])['signal'].shift(1)\n",
    "\n",
    "# add a column called 'good_news' that is 1 if the previous signal is 5 or more and 0 otherwise\n",
    "sim_all.loc[sim_all['signal_previous']>=5, 'good_news'] = 1\n",
    "sim_all.loc[sim_all['signal_previous']<5, 'good_news'] = 0\n",
    "\n",
    "# add a column called 'effort_change' that is the difference between effort in the round and effort in the previous round\n",
    "sim_all['effort_change'] = sim_all.groupby(['ind'])['effort'].diff()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the moments for each parametrization (regression parameters for the reaction to good news and bad news)\n",
    "results = []\n",
    "for i in sim_all['parametrization'].unique():\n",
    "    # regression of effort change on signal_previous, good_news, and the interaction of the two\n",
    "    # the regression is run only for round>1 and for parametrization i\n",
    "    results_i = smf.ols('effort_change ~ signal_previous + good_news + signal_previous:good_news', data=sim_all[(sim_all['round']>2) & (sim_all['parametrization']==i)]).fit()\n",
    "    results.append([results_i, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same columns for updates\n",
    "updates['signal_previous'] = updates.groupby(['code'])['signal'].shift(1)\n",
    "updates.loc[updates['signal_previous']>=5, 'good_news'] = 1\n",
    "updates.loc[updates['signal_previous']<5, 'good_news'] = 0\n",
    "updates['effort_change'] = updates.groupby(['code'])['effort'].diff()\n",
    "\n",
    "# run the regression for the observed data\n",
    "results_obs = smf.ols('effort_change ~ signal_previous + good_news + signal_previous:good_news', data=updates[(updates['round_number']>1)]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coefficients from the regression of the observed data\n",
    "coeff_obs = results_obs.params\n",
    "\n",
    "# weighting matrix of size 4\n",
    "W = np.identity(4)\n",
    "\n",
    "# get the coefficients from the regression of the simulated data and get the value of the objective function\n",
    "quad_form_value = []\n",
    "for i in range(len(results)):\n",
    "    # the coefficients in the simulation for parametrization i\n",
    "    coeff_sim = ((results[i][0].params - results_obs.params).T)@ W @(results[i][0].params - results_obs.params)\n",
    "    quad_form_value.append([coeff_sim, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the list into a dataframe\n",
    "quad_form_value = pd.DataFrame(quad_form_value, columns=['quad_form_value', 'parametrization'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the parametrization for which the objective function is minimized\n",
    "min_index = quad_form_value['quad_form_value'].idxmin()\n",
    "\n",
    "# get the row from parametrization for which \n",
    "sim_all[sim_all['parametrization']==min_index][['c_H', 'c_M', 'c_L']].groupby(['c_H', 'c_M', 'c_L']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[min_index][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=sim_all[sim_all['parametrization']==min_index], x='signal_previous', y='effort_change', hue='good_news', \n",
    "           scatter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=updates[updates['treatment']=='ego'], x='signal_previous', y='effort_change', hue='good_news', \n",
    "           scatter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = smf.ols('effort_change ~ signal_previous + good_news + signal_previous:good_news', data=updates[(updates['round_number']>2)]).fit()\n",
    "\n",
    "data_reg.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
