{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data for all the Ego sessions separately from all the stereotype sessions. I start with ego sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/pp86wz7x4h514cs2lxtvtq3c0000gn/T/ipykernel_64856/2785836866.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ego_wide['treatment'] = 'ego'\n",
      "/var/folders/fz/pp86wz7x4h514cs2lxtvtq3c0000gn/T/ipykernel_64856/2785836866.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ego_wide.reset_index(inplace=True)\n",
      "/var/folders/fz/pp86wz7x4h514cs2lxtvtq3c0000gn/T/ipykernel_64856/2785836866.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  stereo_wide['treatment'] = 'stereotype'\n"
     ]
    }
   ],
   "source": [
    "# import the data in wide format for eah session\n",
    "session1 = pd.read_csv(\"../Data/session1_ego.csv\")\n",
    "session2 = pd.read_csv(\"../Data/session2_ego.csv\")\n",
    "session3 = pd.read_csv(\"../Data/session3_ego.csv\")\n",
    "session4 = pd.read_csv(\"../Data/session4_ego.csv\")\n",
    "\n",
    "# concatenate the sessions\n",
    "ego_wide = pd.concat([session1, session2, session3, session4], axis=0, sort=False)\n",
    "\n",
    "ego_wide['treatment'] = 'ego'\n",
    "ego_wide.reset_index(inplace=True)\n",
    "\n",
    "# import the stereotype data in wide format\n",
    "session5 = pd.read_csv(\"../Data/session5_stereo.csv\")\n",
    "session6 = pd.read_csv(\"../Data/session6_stereo.csv\")\n",
    "session7 = pd.read_csv(\"../Data/session7_stereo.csv\")\n",
    "session8 = pd.read_csv(\"../Data/session8_stereo.csv\")\n",
    "\n",
    "stereo_wide = pd.concat([session5, session6, session7, session8], axis=0, sort=False)\n",
    "stereo_wide['treatment'] = 'stereotype'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the data frame ego_wide, select all the columns that have names that start with 'Quizzes' and append the column 'participant.code\n",
    "quiz_cols = [col for col in ego_wide.columns if 'Quizzes' in col]+['participant.code', 'treatment']\n",
    "\n",
    "\n",
    "# from the data frame ego_wide, select all the columns that have names that start with 'participant.'\n",
    "participant_cols = [col for col in ego_wide.columns if 'participant' in col]+['participant.code']\n",
    "\n",
    "# from the data frame ego_wide, select all the columns that have names that start with 'session.'\n",
    "session_cols = [col for col in ego_wide.columns if 'session' in col]+['participant.code']\n",
    "\n",
    "# from the data frame ego_wide, select all the columns that have names that start with 'Signals.'\n",
    "signal_cols = [col for col in ego_wide.columns if 'Signals' in col]+['participant.code']\n",
    "\n",
    "# from the data frame ego_wide, select all the columns that have names that start with 'SignalsOther.'\n",
    "signal_other_cols = [col for col in ego_wide.columns if 'SignalsOther' in col]+['participant.code']\n",
    "\n",
    "# from the data frame ego_wide, select all the columns that have names that start with 'Questionnaire.'\n",
    "questionnaire_cols = [col for col in ego_wide.columns if 'Questionnaire' in col]+['participant.code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data frame ego_wide into 6 data frames using the columns we just selected\n",
    "ego_quiz = ego_wide[quiz_cols]\n",
    "ego_participant = ego_wide[participant_cols]\n",
    "ego_session = ego_wide[session_cols]\n",
    "ego_signal = ego_wide[signal_cols]\n",
    "ego_signal_other = ego_wide[signal_other_cols] # this has no information for the ego treatment\n",
    "ego_questionnaire = ego_wide[questionnaire_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz Scores\n",
    "First I will clean the data for the first part of the experiment to get only the true scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ego_quiz rename all the columns to remove the prefix 'Quizzes'\n",
    "ego_quiz.columns = [col.replace('Quizzes.','') for col in ego_quiz.columns]\n",
    "# for ego_quiz rename all the columns to remove the prefix 'player'\n",
    "ego_quiz.columns = [col.replace('player.','') for col in ego_quiz.columns]\n",
    "# drop all the columns that have either 'group.' or 'subsession.' in the name\n",
    "ego_quiz = ego_quiz[[col for col in ego_quiz.columns if 'group.' not in col and 'subsession.' not in col]]\n",
    "# melt the data making the participant code the id variable\n",
    "ego_quiz_long = pd.melt(ego_quiz, id_vars=['participant.code'])\n",
    "# split the variable column into two columns, one for the round_number and one for the question\n",
    "ego_quiz_long[['round_number','variable_name']] = ego_quiz_long['variable'].str.split('.', expand=True)\n",
    "# drop the column variable with the long names\n",
    "ego_quiz_long = ego_quiz_long.drop('variable', axis=1)\n",
    "# reshape ego_quiz_long from long to wide format by making each of the values in variable_name a column\n",
    "ego_quiz_wide = ego_quiz_long.pivot(index=['participant.code','round_number'], columns=['variable_name'], values='value')\n",
    "# make a table that has only the score for each topic and the participant code\n",
    "ego_scores = ego_quiz_wide[['topic', 'score']]\n",
    "# reset the index so that participant_code is just another colum\n",
    "ego_scores.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant level variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all the other variables withoutht the 'participant.' prefix\n",
    "ego_participant.columns = [col.replace('participant.','') for col in ego_participant.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The variables from the main part of the experiment\n",
    "This table has all the effort choices and signal realizations round by round. It also has the beliefs about their score and the buttons clicked for the type matixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ego_signal drop all the columns that have the 'SignalsOther.' prefix\n",
    "ego_signal = ego_signal[[col for col in ego_signal.columns if 'SignalsOther.' not in col]]\n",
    "\n",
    "# remove the 'Signals.' prefix from all the column names and the 'participant.' prefix from the code column\n",
    "ego_signal.columns = [col.replace('Signals.','') for col in ego_signal.columns]\n",
    "ego_signal.columns = [col.replace('participant.','') for col in ego_signal.columns]\n",
    "# replace the 'player.' in the names of the columns\n",
    "ego_signal.columns = [col.replace('player.', '') for col in ego_signal.columns]\n",
    "\n",
    "# drop the group and subsession level columns\n",
    "ego_signal = ego_signal[[col for col in ego_signal.columns if 'group.' not in col and '.subsession' not in col]]\n",
    "\n",
    "# melt the data set making code the id column. then split all the variable names\n",
    "ego_signal_long = pd.melt(ego_signal, id_vars='code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the variable column into two columns, one for the round_number and one for the question\n",
    "ego_signal_long[['round_number','variable_name']] = ego_signal_long['variable'].str.split('.', expand=True)\n",
    "# drop the column variable with the long names\n",
    "ego_signal_long = ego_signal_long.drop('variable', axis=1)\n",
    "\n",
    "# reshape ego_signal_long from long to wide format by making each of the values in variable_name a column\n",
    "ego_signal_wide = ego_signal_long.pivot(index=['code','round_number'], columns=['variable_name'], values='value')\n",
    "ego_signal_wide.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "beliefs = ego_signal_wide.loc[ego_signal_wide['science_belief']>=0, \n",
    "                    ['code','science_belief', 'us_belief', 'math_belief', 'verbal_belief', 'pop_belief', 'sports_belief',\n",
    "                    'science_certainty', 'us_certainty', 'math_certainty', 'verbal_certainty', 'pop_certainty', 'sports_certainty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the round_numbers range from 1 to 60. I want all of them to range from 1 to 11 by setting 11 to 1, 21 to 1, 12 to 2, etc.\n",
    "ego_signal_wide['round_number'] = ego_signal_wide['round_number'].astype(int)\n",
    "\n",
    "ego_signal_wide['round_number'].replace([12,23,34,45,56], 1, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([13,24,35,46,57], 2, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([14,25,36,47,58], 3, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([15,26,37,48,59], 4, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([16,27,38,49,60], 5, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([17,28,39,50,61], 6, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([18,29,40,51,62], 7, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([19,30,41,52,63], 8, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([20,31,42,53,64], 9, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([21,32,43,54,65], 10, inplace=True)\n",
    "ego_signal_wide['round_number'].replace([22,33,44,55,66], 11, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the signal stage by topic. \n",
    "For all participants, they got the same exogenous rate and the same order of signals for each topic.\n",
    "I will then merge the topics that have the same exchange rate and the same order of signals.\n",
    "\n",
    "there are nine combinations of type and rate that each participant could have had in each topic. Those 9 pairs are the ones I am interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego_science = ego_signal_wide.loc[(ego_signal_wide['effort']>=0) & (ego_signal_wide['topic']=='Science and Technology'), \n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'science_score', 'topic', 'signal']]\n",
    "# impute the values for science_belief and the science_certainty from the table beliefs\n",
    "ego_science = ego_science.merge(beliefs[['code', 'science_belief', 'science_certainty']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "ego_science.loc[ego_science['science_score']>15, 'type'] = '2'\n",
    "ego_science.loc[ego_science['science_score']<=15, 'type'] = '1'\n",
    "ego_science.loc[ego_science['science_score']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for math exactly as ego_science but with the math score and belief\n",
    "ego_math = ego_signal_wide.loc[(ego_signal_wide['effort']>=0) & (ego_signal_wide['topic']=='Math'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'math_score', 'topic', 'signal']]\n",
    "# impute the values for math_belief and the math_certainty from the table beliefs\n",
    "ego_math = ego_math.merge(beliefs[['code', 'math_belief', 'math_certainty']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "ego_math.loc[ego_math['math_score']>15, 'type'] = '2'\n",
    "ego_math.loc[ego_math['math_score']<=15, 'type'] = '1'\n",
    "ego_math.loc[ego_math['math_score']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as ego_science but with the verbal score and belief\n",
    "ego_verbal = ego_signal_wide.loc[(ego_signal_wide['effort']>=0) & (ego_signal_wide['topic']=='Verbal'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'verbal_score', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "ego_verbal = ego_verbal.merge(beliefs[['code', 'verbal_belief', 'verbal_certainty']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "ego_verbal.loc[ego_verbal['verbal_score']>15, 'type'] = '2'\n",
    "ego_verbal.loc[ego_verbal['verbal_score']<=15, 'type'] = '1'\n",
    "ego_verbal.loc[ego_verbal['verbal_score']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as ego_science but with the verbal score and belief\n",
    "ego_pop = ego_signal_wide.loc[(ego_signal_wide['effort']>=0) & (ego_signal_wide['topic']=='Pop-Culture and Art'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'pop_score', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "ego_pop = ego_pop.merge(beliefs[['code', 'pop_belief', 'pop_certainty']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "ego_pop.loc[ego_pop['pop_score']>15, 'type'] = '2'\n",
    "ego_pop.loc[ego_pop['pop_score']<=15, 'type'] = '1'\n",
    "ego_pop.loc[ego_pop['pop_score']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as ego_science but with the verbal score and belief\n",
    "ego_sports = ego_signal_wide.loc[(ego_signal_wide['effort']>=0) & (ego_signal_wide['topic']=='Sports and Video Games'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'sports_score', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "ego_sports = ego_sports.merge(beliefs[['code', 'sports_belief', 'sports_certainty']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "ego_sports.loc[ego_sports['sports_score']>15, 'type'] = '2'\n",
    "ego_sports.loc[ego_sports['sports_score']<=15, 'type'] = '1'\n",
    "ego_sports.loc[ego_sports['sports_score']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as ego_science but with the verbal score and belief\n",
    "ego_us = ego_signal_wide.loc[(ego_signal_wide['effort']>=0) & (ego_signal_wide['topic']=='US Geography'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'us_score', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "ego_us = ego_us.merge(beliefs[['code', 'us_belief', 'us_certainty']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "ego_us.loc[ego_us['us_score']>15, 'type'] = '2'\n",
    "ego_us.loc[ego_us['us_score']<=15, 'type'] = '1'\n",
    "ego_us.loc[ego_us['us_score']<6, 'type'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the rate values for each topic\n",
    "The rate values are saved at the session level and are the same across all rounds because the seed was set at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the ego session data frame select only the columns that we will use\n",
    "ego_session = ego_session[['participant.id_in_session', \n",
    "                            'session.code', \n",
    "                            'session.w_verbal', \n",
    "                            'session.w_math', \n",
    "                            'session.w_pop',\n",
    "                            'session.w_science',\n",
    "                            'session.w_sports',\n",
    "                            'session.w_us']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in ego_session remove the prefixes 'participant.' and 'session.' from the column names\n",
    "ego_session.columns = [col.replace('participant.','') for col in ego_session.columns]\n",
    "ego_session.columns = [col.replace('session.','') for col in ego_session.columns]\n",
    "# add a column to each of the topics tables with the corresponding value of w from the ego_session table\n",
    "ego_science['rate']=ego_session['w_science'][0]\n",
    "ego_math['rate']=ego_session['w_math'][0]\n",
    "ego_verbal['rate']=ego_session['w_verbal'][0]\n",
    "ego_pop['rate']=ego_session['w_pop'][0]\n",
    "ego_sports['rate']=ego_session['w_sports'][0]\n",
    "ego_us['rate']=ego_session['w_us'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## name homogenization\n",
    "Make all the toipic tables have the same column names so that they can be merged into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ego_science remove the prefix 'science_' from the column names that have it\n",
    "ego_science.columns = [col.replace('science_','') for col in ego_science.columns]\n",
    "\n",
    "# from ego_math remove the prefix 'math_' from the column names that have it\n",
    "ego_math.columns = [col.replace('math_','') for col in ego_math.columns]\n",
    "\n",
    "# from ego_verbal remove the prefix 'verbal_' from the column names that have it\n",
    "ego_verbal.columns = [col.replace('verbal_','') for col in ego_verbal.columns]\n",
    "\n",
    "# from ego_pop remove the prefix 'pop_' from the column names that have it\n",
    "ego_pop.columns = [col.replace('pop_','') for col in ego_pop.columns]\n",
    "\n",
    "# from ego_sports remove the prefix 'sports_' from the column names that have it\n",
    "ego_sports.columns = [col.replace('sports_','') for col in ego_sports.columns]\n",
    "\n",
    "# from ego_us remove the prefix 'us_' from the column names that have it\n",
    "ego_us.columns = [col.replace('us_','') for col in ego_us.columns]\n",
    "\n",
    "# stack all the topic tables into one larger data frame called ego_updates\n",
    "ego_updates = pd.concat([ego_science, ego_math, ego_verbal, ego_pop, ego_sports, ego_us])\n",
    "ego_updates.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate into 9 types:\n",
    "low type, low rate\n",
    "\n",
    "low type, medium rate\n",
    "\n",
    "low type, high rate\n",
    "\n",
    "medium type, low rate\n",
    "\n",
    "medium type, medium rate\n",
    "\n",
    "medium type, high rate\n",
    "\n",
    "high type, low rate\n",
    "\n",
    "high type, medium rate\n",
    "\n",
    "high type, high rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a colun that indicates the treatment\n",
    "ego_updates['treatment'] = 'ego'\n",
    "\n",
    "# turn the type column into an integer\n",
    "ego_updates['type'] = ego_updates['type'].astype(int)\n",
    "\n",
    "# add a column that indicates if the participant was overconfident\n",
    "ego_updates['overconfident'] = 0\n",
    "ego_updates.loc[ego_updates['type']<ego_updates['belief'], 'overconfident'] = 1\n",
    "\n",
    "# add a column that indicates if the participant was underconfident\n",
    "ego_updates['underconfident'] = 0\n",
    "ego_updates.loc[ego_updates['type']>ego_updates['belief'], 'underconfident'] = 1\n",
    "\n",
    "# add a column that indicates if the participant was correct\n",
    "ego_updates['correct']=0\n",
    "ego_updates.loc[ego_updates['type']==ego_updates['belief'], 'correct'] = 1\n",
    "\n",
    "# create a table for each pair of theta and omega (type and rate) the subindexes are in that order\n",
    "#low types\n",
    "updates_ll = ego_updates.loc[(ego_updates['type']==0) & (ego_updates['rate']==0), :]\n",
    "updates_lm = ego_updates.loc[(ego_updates['type']==0) & (ego_updates['rate']==1), :]\n",
    "updates_lh = ego_updates.loc[(ego_updates['type']==0) & (ego_updates['rate']==2), :]\n",
    "\n",
    "# mid types\n",
    "updates_ml = ego_updates.loc[(ego_updates['type']==1) & (ego_updates['rate']==0), :]\n",
    "updates_mm = ego_updates.loc[(ego_updates['type']==1) & (ego_updates['rate']==1), :]\n",
    "updates_mh = ego_updates.loc[(ego_updates['type']==1) & (ego_updates['rate']==2), :]\n",
    "\n",
    "# high types\n",
    "updates_hl = ego_updates.loc[(ego_updates['type']==2) & (ego_updates['rate']==0), :]\n",
    "updates_hm = ego_updates.loc[(ego_updates['type']==2) & (ego_updates['rate']==1), :]\n",
    "updates_hh = ego_updates.loc[(ego_updates['type']==2) & (ego_updates['rate']==2), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>round_number</th>\n",
       "      <th>effort</th>\n",
       "      <th>fails</th>\n",
       "      <th>last_button</th>\n",
       "      <th>score</th>\n",
       "      <th>topic</th>\n",
       "      <th>signal</th>\n",
       "      <th>belief</th>\n",
       "      <th>certainty</th>\n",
       "      <th>type</th>\n",
       "      <th>rate</th>\n",
       "      <th>treatment</th>\n",
       "      <th>overconfident</th>\n",
       "      <th>underconfident</th>\n",
       "      <th>correct</th>\n",
       "      <th>misspecification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0m2xzxgv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0m2xzxgv</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0m2xzxgv</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0m2xzxgv</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0m2xzxgv</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Science and Technology</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>zap4p51l</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US Geography</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>zap4p51l</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US Geography</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>zap4p51l</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US Geography</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>zap4p51l</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US Geography</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>zap4p51l</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>US Geography</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ego</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2970 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          code  round_number effort fails last_button score  \\\n",
       "0     0m2xzxgv             1      1     9           2   9.0   \n",
       "1     0m2xzxgv             2      1     7           1   9.0   \n",
       "2     0m2xzxgv             3      2    10           2   9.0   \n",
       "3     0m2xzxgv             4      0     7           0   9.0   \n",
       "4     0m2xzxgv             5      0     8           1   9.0   \n",
       "...        ...           ...    ...   ...         ...   ...   \n",
       "2965  zap4p51l             7      1     9           0   5.0   \n",
       "2966  zap4p51l             8      0     9           0   5.0   \n",
       "2967  zap4p51l             9      2    10           0   5.0   \n",
       "2968  zap4p51l            10      1     5           0   5.0   \n",
       "2969  zap4p51l            11      1     5           0   5.0   \n",
       "\n",
       "                       topic signal belief certainty  type  rate treatment  \\\n",
       "0     Science and Technology      1      0        75     1     0       ego   \n",
       "1     Science and Technology      3      0        75     1     0       ego   \n",
       "2     Science and Technology      0      0        75     1     0       ego   \n",
       "3     Science and Technology      3      0        75     1     0       ego   \n",
       "4     Science and Technology      2      0        75     1     0       ego   \n",
       "...                      ...    ...    ...       ...   ...   ...       ...   \n",
       "2965            US Geography      1      0        75     0     1       ego   \n",
       "2966            US Geography      1      0        75     0     1       ego   \n",
       "2967            US Geography      0      0        75     0     1       ego   \n",
       "2968            US Geography      5      0        75     0     1       ego   \n",
       "2969            US Geography      5      0        75     0     1       ego   \n",
       "\n",
       "      overconfident  underconfident  correct misspecification  \n",
       "0                 0               1        0            under  \n",
       "1                 0               1        0            under  \n",
       "2                 0               1        0            under  \n",
       "3                 0               1        0            under  \n",
       "4                 0               1        0            under  \n",
       "...             ...             ...      ...              ...  \n",
       "2965              0               0        1          correct  \n",
       "2966              0               0        1          correct  \n",
       "2967              0               0        1          correct  \n",
       "2968              0               0        1          correct  \n",
       "2969              0               0        1          correct  \n",
       "\n",
       "[2970 rows x 17 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ego_updates.loc[ego_updates['overconfident']==1, 'misspecification'] = 'over'\n",
    "ego_updates.loc[ego_updates['underconfident']==1, 'misspecification'] = 'under'\n",
    "ego_updates.loc[ego_updates['correct']==1, 'misspecification'] = 'correct'\n",
    "ego_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Stereotypes treatment\n",
    "do the same for all tables and instead of using signals, use SignalsOther. Then merge the two tables together with the column that indicates the treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the data frame select all the columns that have names that start with 'Quizzes' and append the column 'participant.code\n",
    "quiz_cols = [col for col in stereo_wide.columns if 'Quizzes' in col]+['participant.code', 'treatment']\n",
    "\n",
    "\n",
    "# from the data frame select all the columns that have names that start with 'participant.'\n",
    "participant_cols = [col for col in stereo_wide.columns if 'participant' in col]+['participant.code']\n",
    "\n",
    "# from the data frame select all the columns that have names that start with 'session.'\n",
    "session_cols = [col for col in stereo_wide.columns if 'session' in col]+['participant.code']\n",
    "\n",
    "# from the data frame select all the columns that have names that start with 'Signals.'\n",
    "signal_cols = [col for col in stereo_wide.columns if 'Signals' in col]+['participant.code']\n",
    "\n",
    "# from the data frame select all the columns that have names that start with 'SignalsOther.'\n",
    "signal_other_cols = [col for col in stereo_wide.columns if 'SignalsOther' in col]+['participant.code']\n",
    "\n",
    "# from the data frame select all the columns that have names that start with 'Questionnaire.'\n",
    "questionnaire_cols = [col for col in stereo_wide.columns if 'Questionnaire' in col]+['participant.code']\n",
    "\n",
    "# split the data frame stereo_wide into 6 data frames using the columns we just selected\n",
    "stereo_quiz = stereo_wide[quiz_cols]\n",
    "stereo_participant = stereo_wide[participant_cols]\n",
    "stereo_session = stereo_wide[session_cols]\n",
    "stereo_signal = stereo_wide[signal_cols] # this has no information for the stereotype treatment\n",
    "stereo_signal_other = stereo_wide[signal_other_cols] \n",
    "stereo_questionnaire = stereo_wide[questionnaire_cols]\n",
    "\n",
    "# for stereo_quiz rename all the columns to remove the prefix 'Quizzes'\n",
    "stereo_quiz.columns = [col.replace('Quizzes.','') for col in stereo_quiz.columns]\n",
    "# for stereo_quiz rename all the columns to remove the prefix 'player'\n",
    "stereo_quiz.columns = [col.replace('player.','') for col in stereo_quiz.columns]\n",
    "\n",
    "# drop all the columns that have either 'group.' or 'subsession.' in the name\n",
    "stereo_quiz = stereo_quiz[[col for col in stereo_quiz.columns if 'group.' not in col and 'subsession.' not in col]]\n",
    "# melt the data making the participant code the id variable\n",
    "stereo_quiz_long = pd.melt(stereo_quiz, id_vars=['participant.code'])\n",
    "# split the variable column into two columns, one for the round_number and one for the question\n",
    "stereo_quiz_long[['round_number','variable_name']] = stereo_quiz_long['variable'].str.split('.', expand=True)\n",
    "# drop the column variable with the long names\n",
    "stereo_quiz_long = stereo_quiz_long.drop('variable', axis=1)\n",
    "# reshape stereo_quiz_long from long to wide format by making each of the values in variable_name a column\n",
    "stereo_quiz_wide = stereo_quiz_long.pivot(index=['participant.code','round_number'], columns=['variable_name'], values='value')\n",
    "# make a table that has only the score for each topic and the participant code\n",
    "stereo_scores = stereo_quiz_wide[['topic', 'score']]\n",
    "# reset the index so that participant_code is just another colum\n",
    "stereo_scores.reset_index(inplace=True)\n",
    "\n",
    "# Rename all the other variables withoutht the 'participant.' prefix\n",
    "stereo_participant.columns = [col.replace('participant.','') for col in stereo_participant.columns]\n",
    "\n",
    "### Main part of the experiment for the sterotype treatment\n",
    "\n",
    "# remove the 'Signals.' prefix from all the column names and the 'participant.' prefix from the code column\n",
    "stereo_signal_other.columns = [col.replace('SignalsOther.','') for col in stereo_signal_other.columns]\n",
    "stereo_signal_other.columns = [col.replace('participant.','') for col in stereo_signal_other.columns]\n",
    "# replace the 'player.' in the names of the columns\n",
    "stereo_signal_other.columns = [col.replace('player.', '') for col in stereo_signal_other.columns]\n",
    "\n",
    "# drop the group and subsession level columns\n",
    "stereo_signal_other = stereo_signal_other[[col for col in stereo_signal_other.columns if 'group.' not in col and '.subsession' not in col]]\n",
    "\n",
    "# melt the data set making code the id column. then split all the variable names\n",
    "stereo_signal_other_long = pd.melt(stereo_signal_other, id_vars='code')\n",
    "\n",
    "# split the variable column into two columns, one for the round_number and one for the question\n",
    "stereo_signal_other_long[['round_number','variable_name']] = stereo_signal_other_long['variable'].str.split('.', expand=True)\n",
    "# drop the column variable with the long names\n",
    "stereo_signal_other_long = stereo_signal_other_long.drop('variable', axis=1)\n",
    "\n",
    "# reshape stereo_signal_other_long from long to wide format by making each of the values in variable_name a column\n",
    "stereo_signal_other_wide = stereo_signal_other_long.pivot(index=['code','round_number'], columns=['variable_name'], values='value')\n",
    "stereo_signal_other_wide.reset_index(inplace=True)\n",
    "\n",
    "beliefs_other = stereo_signal_other_wide.loc[stereo_signal_other_wide['science_belief_other']>=0, \n",
    "                    ['code','science_belief_other', 'us_belief_other', 'math_belief_other', 'verbal_belief_other', \n",
    "                    'pop_belief_other', 'sports_belief_other',\n",
    "                    'science_certainty_other', 'us_certainty_other', 'math_certainty_other', 'verbal_certainty_other', \n",
    "                    'pop_certainty_other', 'sports_certainty_other']]\n",
    "\n",
    "# the round_numbers range from 1 to 60. I want all of them to range from 1 to 10 by setting 11 to 1, 21 to 1, 12 to 2, etc.\n",
    "stereo_signal_other_wide['round_number'] = stereo_signal_other_wide['round_number'].astype(int)\n",
    "\n",
    "stereo_signal_other_wide['round_number'].replace([12,23,34,45,56], 1, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([13,24,35,46,57], 2, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([14,25,36,47,58], 3, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([15,26,37,48,59], 4, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([16,27,38,49,60], 5, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([17,28,39,50,61], 6, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([18,29,40,51,62], 7, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([19,30,41,52,63], 8, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([20,31,42,53,64], 9, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([21,32,43,54,65], 10, inplace=True)\n",
    "stereo_signal_other_wide['round_number'].replace([22,33,44,55,66], 11, inplace=True)\n",
    "\n",
    "# split by topic\n",
    "\n",
    "st_science = stereo_signal_other_wide.loc[(stereo_signal_other_wide['effort']>=0) & (stereo_signal_other_wide['topic']=='Science and Technology'), \n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'science_other', 'topic', 'signal']]\n",
    "# impute the values for science_belief and the science_certainty from the table beliefs\n",
    "st_science = st_science.merge(beliefs_other[['code', 'science_belief_other', 'science_certainty_other']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "st_science.loc[st_science['science_other']>15, 'type'] = '2'\n",
    "st_science.loc[st_science['science_other']<=15, 'type'] = '1'\n",
    "st_science.loc[st_science['science_other']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for math exactly as st_science but with the math score and belief\n",
    "st_math = stereo_signal_other_wide.loc[(stereo_signal_other_wide['effort']>=0) & (stereo_signal_other_wide['topic']=='Math'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'math_other', 'topic', 'signal']]\n",
    "# impute the values for math_belief and the math_certainty from the table beliefs\n",
    "st_math = st_math.merge(beliefs_other[['code', 'math_belief_other', 'math_certainty_other']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "st_math.loc[st_math['math_other']>15, 'type'] = '2'\n",
    "st_math.loc[st_math['math_other']<=15, 'type'] = '1'\n",
    "st_math.loc[st_math['math_other']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as st_science but with the verbal score and belief\n",
    "st_verbal = stereo_signal_other_wide.loc[(stereo_signal_other_wide['effort']>=0) & (stereo_signal_other_wide['topic']=='Verbal'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'verbal_other', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "st_verbal = st_verbal.merge(beliefs_other[['code', 'verbal_belief_other', 'verbal_certainty_other']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "st_verbal.loc[st_verbal['verbal_other']>15, 'type'] = '2'\n",
    "st_verbal.loc[st_verbal['verbal_other']<=15, 'type'] = '1'\n",
    "st_verbal.loc[st_verbal['verbal_other']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as st_science but with the verbal score and belief\n",
    "st_pop = stereo_signal_other_wide.loc[(stereo_signal_other_wide['effort']>=0) & (stereo_signal_other_wide['topic']=='Pop-Culture and Art'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'pop_other', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "st_pop = st_pop.merge(beliefs_other[['code', 'pop_belief_other', 'pop_certainty_other']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "st_pop.loc[st_pop['pop_other']>15, 'type'] = '2'\n",
    "st_pop.loc[st_pop['pop_other']<=15, 'type'] = '1'\n",
    "st_pop.loc[st_pop['pop_other']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as st_science but with the verbal score and belief\n",
    "st_sports = stereo_signal_other_wide.loc[(stereo_signal_other_wide['effort']>=0) & (stereo_signal_other_wide['topic']=='Sports and Video Games'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'sports_other', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "st_sports = st_sports.merge(beliefs_other[['code', 'sports_belief_other', 'sports_certainty_other']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "st_sports.loc[st_sports['sports_other']>15, 'type'] = '2'\n",
    "st_sports.loc[st_sports['sports_other']<=15, 'type'] = '1'\n",
    "st_sports.loc[st_sports['sports_other']<6, 'type'] = '0'\n",
    "\n",
    "# make a data frame for verbal exactly as st_science but with the verbal score and belief\n",
    "st_us = stereo_signal_other_wide.loc[(stereo_signal_other_wide['effort']>=0) & (stereo_signal_other_wide['topic']=='US Geography'),\n",
    "                    ['code', 'round_number', 'effort', 'fails', 'last_button', 'us_other', 'topic', 'signal']]\n",
    "# impute the values for verbal_belief and the verbal_certainty from the table beliefs\n",
    "st_us = st_us.merge(beliefs_other[['code', 'us_belief_other', 'us_certainty_other']], on='code', how='left')\n",
    "\n",
    "# add a column with the type according to the science score\n",
    "st_us.loc[st_us['us_other']>15, 'type'] = '2'\n",
    "st_us.loc[st_us['us_other']<=15, 'type'] = '1'\n",
    "st_us.loc[st_us['us_other']<6, 'type'] = '0'\n",
    "\n",
    "# from the ego session data frame select only the columns that we will use\n",
    "stereo_session = stereo_session[['participant.id_in_session', \n",
    "                            'session.code', \n",
    "                            'session.w_verbal', \n",
    "                            'session.w_math', \n",
    "                            'session.w_pop',\n",
    "                            'session.w_science',\n",
    "                            'session.w_sports',\n",
    "                            'session.w_us']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable_name</th>\n",
       "      <th>code</th>\n",
       "      <th>round_number</th>\n",
       "      <th>effort</th>\n",
       "      <th>fails</th>\n",
       "      <th>gender_other</th>\n",
       "      <th>high_button</th>\n",
       "      <th>id_in_group</th>\n",
       "      <th>last_button</th>\n",
       "      <th>low_button</th>\n",
       "      <th>math_belief_other</th>\n",
       "      <th>...</th>\n",
       "      <th>us_belief_other</th>\n",
       "      <th>us_belief_self</th>\n",
       "      <th>us_certainty_other</th>\n",
       "      <th>us_certainty_self</th>\n",
       "      <th>us_other</th>\n",
       "      <th>verbal_belief_other</th>\n",
       "      <th>verbal_belief_self</th>\n",
       "      <th>verbal_certainty_other</th>\n",
       "      <th>verbal_certainty_self</th>\n",
       "      <th>verbal_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0kxsrg73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0kxsrg73</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0kxsrg73</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0kxsrg73</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0kxsrg73</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>zwzznpo6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>zwzznpo6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>zwzznpo6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>zwzznpo6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>zwzznpo6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable_name      code  round_number effort fails gender_other high_button  \\\n",
       "0              0kxsrg73             1      0     8       Female           2   \n",
       "1              0kxsrg73            10      0     8          NaN           0   \n",
       "2              0kxsrg73            11      0     6          NaN           1   \n",
       "11             0kxsrg73             2      0     4          NaN           0   \n",
       "22             0kxsrg73             3      2    10          NaN           1   \n",
       "...                 ...           ...    ...   ...          ...         ...   \n",
       "2121           zwzznpo6             7      0     3          NaN           1   \n",
       "2122           zwzznpo6             8      0     5          NaN           1   \n",
       "2124           zwzznpo6             9      0     6          NaN           1   \n",
       "2125           zwzznpo6            10      1     7          NaN           0   \n",
       "2126           zwzznpo6            11      0     6          NaN           0   \n",
       "\n",
       "variable_name id_in_group last_button low_button math_belief_other  ...  \\\n",
       "0                       4           2          2                 2  ...   \n",
       "1                       4           0          1               NaN  ...   \n",
       "2                       4           2          0               NaN  ...   \n",
       "11                      4           0          1               NaN  ...   \n",
       "22                      4           0          1               NaN  ...   \n",
       "...                   ...         ...        ...               ...  ...   \n",
       "2121                    7           2          0               NaN  ...   \n",
       "2122                    7           2          0               NaN  ...   \n",
       "2124                    7           2          0               NaN  ...   \n",
       "2125                    7           1          0               NaN  ...   \n",
       "2126                    7           1          0               NaN  ...   \n",
       "\n",
       "variable_name us_belief_other us_belief_self us_certainty_other  \\\n",
       "0                           1              0                 50   \n",
       "1                         NaN            NaN                NaN   \n",
       "2                         NaN            NaN                NaN   \n",
       "11                        NaN            NaN                NaN   \n",
       "22                        NaN            NaN                NaN   \n",
       "...                       ...            ...                ...   \n",
       "2121                      NaN            NaN                NaN   \n",
       "2122                      NaN            NaN                NaN   \n",
       "2124                      NaN            NaN                NaN   \n",
       "2125                      NaN            NaN                NaN   \n",
       "2126                      NaN            NaN                NaN   \n",
       "\n",
       "variable_name us_certainty_self us_other verbal_belief_other  \\\n",
       "0                            75       11                   1   \n",
       "1                           NaN      NaN                 NaN   \n",
       "2                           NaN      NaN                 NaN   \n",
       "11                          NaN      NaN                 NaN   \n",
       "22                          NaN      NaN                 NaN   \n",
       "...                         ...      ...                 ...   \n",
       "2121                        NaN      NaN                 NaN   \n",
       "2122                        NaN      NaN                 NaN   \n",
       "2124                        NaN      NaN                 NaN   \n",
       "2125                        NaN      NaN                 NaN   \n",
       "2126                        NaN      NaN                 NaN   \n",
       "\n",
       "variable_name verbal_belief_self verbal_certainty_other verbal_certainty_self  \\\n",
       "0                              0                     75                    75   \n",
       "1                            NaN                    NaN                   NaN   \n",
       "2                            NaN                    NaN                   NaN   \n",
       "11                           NaN                    NaN                   NaN   \n",
       "22                           NaN                    NaN                   NaN   \n",
       "...                          ...                    ...                   ...   \n",
       "2121                         NaN                    NaN                   NaN   \n",
       "2122                         NaN                    NaN                   NaN   \n",
       "2124                         NaN                    NaN                   NaN   \n",
       "2125                         NaN                    NaN                   NaN   \n",
       "2126                         NaN                    NaN                   NaN   \n",
       "\n",
       "variable_name verbal_other  \n",
       "0                        4  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "11                     NaN  \n",
       "22                     NaN  \n",
       "...                    ...  \n",
       "2121                   NaN  \n",
       "2122                   NaN  \n",
       "2124                   NaN  \n",
       "2125                   NaN  \n",
       "2126                   NaN  \n",
       "\n",
       "[363 rows x 45 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the rows that are nan in the column 'effort'\n",
    "stereo_signal_other_wide.loc[(stereo_signal_other_wide['round_number']<12) & (stereo_signal_other_wide['topic']=='Science and Technology'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in stereo_session remove the prefixes 'participant.' and 'session.' from the column names\n",
    "stereo_session.columns = [col.replace('participant.','') for col in stereo_session.columns]\n",
    "stereo_session.columns = [col.replace('session.','') for col in stereo_session.columns]\n",
    "# add a column to each of the topics tables with the corresponding value of w from the stereo_session table\n",
    "st_science['rate']=stereo_session['w_science'].unique()[0]\n",
    "st_math['rate']=stereo_session['w_math'].unique()[0]\n",
    "st_verbal['rate']=stereo_session['w_verbal'].unique()[0]\n",
    "st_pop['rate']=stereo_session['w_pop'].unique()[0]\n",
    "st_sports['rate']=stereo_session['w_sports'].unique()[0]\n",
    "st_us['rate']=stereo_session['w_us'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from st_science rename the score_other column to score so that it we can stack across all the topics and the belief and\n",
    "# crtainty columns to not include the topic '_prefix' or the other '_suffix'\n",
    "st_science.rename(columns={'science_other':'score', 'science_belief_other':'belief', 'science_certainty_other':'certainty'}, inplace=True)\n",
    "st_math.rename(columns={'math_other':'score', 'math_belief_other':'belief', 'math_certainty_other':'certainty'}, inplace=True)\n",
    "st_verbal.rename(columns={'verbal_other':'score', 'verbal_belief_other':'belief', 'verbal_certainty_other':'certainty'}, inplace=True)\n",
    "st_pop.rename(columns={'pop_other':'score', 'pop_belief_other':'belief', 'pop_certainty_other':'certainty'}, inplace=True)\n",
    "st_sports.rename(columns={'sports_other':'score', 'sports_belief_other':'belief', 'sports_certainty_other':'certainty'}, inplace=True)\n",
    "st_us.rename(columns={'us_other':'score', 'us_belief_other':'belief', 'us_certainty_other':'certainty'}, inplace=True)\n",
    "\n",
    "\n",
    "# stack all the topic tables into one larger data frame called st_updates\n",
    "st_updates = pd.concat([st_science, st_math, st_verbal, st_pop, st_sports, st_us])\n",
    "st_updates.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a colun that indicates the treatment\n",
    "st_updates['treatment'] = 'stereotype'\n",
    "\n",
    "# turn the type column into an integer\n",
    "st_updates['type'] = st_updates['type'].astype(int)\n",
    "\n",
    "# add a column that indicates if the participant was overconfident\n",
    "st_updates['overconfident'] = 0\n",
    "st_updates.loc[st_updates['type']<st_updates['belief'], 'overconfident'] = 1\n",
    "\n",
    "# add a column that indicates if the participant was underconfident\n",
    "st_updates['underconfident'] = 0\n",
    "st_updates.loc[st_updates['type']>st_updates['belief'], 'underconfident'] = 1\n",
    "\n",
    "# add a column that indicates if the participant was correct\n",
    "st_updates['correct']=0\n",
    "st_updates.loc[st_updates['type']==st_updates['belief'], 'correct'] = 1\n",
    "\n",
    "# create a table for each pair of theta and omega (type and rate) the subindexes are in that order\n",
    "#low types\n",
    "updates_ll = st_updates.loc[(st_updates['type']==0) & (st_updates['rate']==0), :]\n",
    "updates_lm = st_updates.loc[(st_updates['type']==0) & (st_updates['rate']==1), :]\n",
    "updates_lh = st_updates.loc[(st_updates['type']==0) & (st_updates['rate']==2), :]\n",
    "\n",
    "# mid types\n",
    "updates_ml = st_updates.loc[(st_updates['type']==1) & (st_updates['rate']==0), :]\n",
    "updates_mm = st_updates.loc[(st_updates['type']==1) & (st_updates['rate']==1), :]\n",
    "updates_mh = st_updates.loc[(st_updates['type']==1) & (st_updates['rate']==2), :]\n",
    "\n",
    "# high types\n",
    "updates_hl = st_updates.loc[(st_updates['type']==2) & (st_updates['rate']==0), :]\n",
    "updates_hm = st_updates.loc[(st_updates['type']==2) & (st_updates['rate']==1), :]\n",
    "updates_hh = st_updates.loc[(st_updates['type']==2) & (st_updates['rate']==2), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_updates.loc[st_updates['overconfident']==1, 'misspecification'] = 'over'\n",
    "st_updates.loc[st_updates['underconfident']==1, 'misspecification'] = 'under'\n",
    "st_updates.loc[st_updates['correct']==1, 'misspecification'] = 'correct'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data from both treatments into a table called updates\n",
    "updates = pd.concat([ego_updates, st_updates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics_ego = ego_wide[['participant.code', \n",
    "                        'participant.gender',\n",
    "                        'participant.nationality']]\n",
    "\n",
    "characteristics_stereo = stereo_wide[['participant.code', \n",
    "                        'participant.gender',\n",
    "                        'participant.nationality']]\n",
    "\n",
    "characteristics = pd.concat([characteristics_ego, characteristics_stereo], axis=0, sort=False)\n",
    "\n",
    "\n",
    "# rename the columns to remove the prefix 'participant.'\n",
    "characteristics.columns = [col.replace('participant.','') for col in characteristics.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data from characteristics with the data from updates on code. keep everything from updates\n",
    "updates = updates.merge(characteristics, on='code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column that turns the misspecification column into a numeric variable. -1 if under, 0 if correct and 1 if over\n",
    "updates['misspecification_num'] = 0\n",
    "updates.loc[updates['misspecification']=='over', 'misspecification_num'] = 1\n",
    "updates.loc[updates['misspecification']=='under', 'misspecification_num'] = -1\n",
    "\n",
    "# save data into a csv file\n",
    "updates.to_csv('../Clean/updates.csv', index=False)\n",
    "ego_updates.to_csv('../Clean/ego_updates.csv', index=False)\n",
    "st_updates.to_csv('../Clean/stereo_updates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0kxsrg73', '1zb27tea', '36b7nxpg', '3cv0gsso', '4d7lvql9',\n",
       "       '4kecnisx', '56op1uib', '6sybrxjn', '6zd6yym2', '78sdphga',\n",
       "       'a22g0du7', 'byf6tjt0', 'cioxyqvq', 'cl0818oa', 'dk93ewke',\n",
       "       'ffd2bxk4', 'g2p53iqv', 'idzf7yro', 'ilooy3i8', 'j3r6tuv8',\n",
       "       'jk70axat', 'jka2nr9v', 'k43107gm', 'ko3jhnbj', 'lmiiifw0',\n",
       "       'n86dcmzu', 'ncvtgyzn', 'oqf1d07l', 'q9jar1of', 'uz5m20q1',\n",
       "       'v3yunf9n', 'wursesku', 'zwzznpo6'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_updates['code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updates[updates['treatment']=='stereotype']['code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
