@article{Barron2021,
   abstract = {Bayes’ statistical rule remains the status quo for modeling belief updating in both normative and descriptive models of behavior under uncertainty. Some recent research has questioned the use of Bayes’ rule in descriptive models of behavior, presenting evidence that people overweight ‘good news’ relative to ‘bad news’ when updating ego-relevant beliefs. In this paper, we present experimental evidence testing whether this ‘good-news, bad-news’ effect is present in a financial decision making context (i.e. a domain that is important for understanding much economic decision making). We find no evidence of asymmetric updating in this domain. In contrast, in our experiment, belief updating is close to the Bayesian benchmark on average. However, we show that this average behavior masks substantial heterogeneity in individual updating behavior. We find no evidence in support of a sizeable subgroup of asymmetric updators.},
   author = {Kai Barron},
   doi = {10.1007/S10683-020-09653-Z/FIGURES/4},
   issn = {15736938},
   issue = {1},
   journal = {Experimental Economics},
   keywords = {Bayes’ rule,Belief measurement,Belief updating,Economic experiments,Motivated beliefs,Proper scoring rules},
   month = {3},
   pages = {31-58},
   publisher = {Springer},
   title = {Belief updating: does the ‘good-news, bad-news’ asymmetry extend to purely financial domains?},
   volume = {24},
   url = {https://link.springer.com/article/10.1007/s10683-020-09653-z},
   year = {2021},
}
@article{Bohren2019,
   abstract = {We model the dynamics of discrimination and show how its evolution can identify the underlying source. We test these theoretical predictions in a field experiment on a large online platform where users post content that is evaluated by other users on the platform. We assign posts to accounts that exogenously vary by gender and evaluation histories. With no prior evaluations, women face significant discrimination. However, following a sequence of positive evaluations , the direction of discrimination reverses: women's posts are favored over men's. Interpreting these results through the lens of our model, this dynamic reversal implies discrimination driven by biased beliefs. (JEL C93, D83, J16, J71) A rich literature has documented discrimination in a wide range of contexts (Bertrand and Duflo 2017). These empirical studies have mostly focused on static settings: individuals are evaluated based on the quality of a single piece of output or a single interaction, with no information on prior evaluations in similar contexts. As prior work has noted, it is difficult to identify the underlying source of discrimination from such static settings, as different sources generate the same patterns of observable behavior (Fang and Moro 2011). In this paper, we develop a theoretical framework to show how the dynamics of discrimination can be used to identify its underlying source, and test these predictions in a field experiment on a large online platform. Consider a setting where individuals repeatedly perform tasks that generate output , and in the process, produce an observable history of evaluations on these tasks. For example, a man and a woman are employed at a firm and are promoted based on},
   author = {By J Aislinn Bohren and Alex Imas and Michael Rosenberg and Nageeb Ali and Linda Babcock and Michael Callen and Hanming Fang and Uri Gneezy and Polina Imas and Nicola Gennaioli and Gregor Jarosch and Emir Kamenica and Gene Kucher and George Loewenstein and Kristof Madarasz and Craig McIntosh and Margaret Meyer and Siqi Pan and Sally Sadoff},
   doi = {10.1257/aer.20171829},
   issue = {10},
   journal = {American Economic Review},
   pages = {3395-3436},
   title = {The Dynamics of Discrimination: Theory and Evidence †},
   volume = {109},
   url = {https://doi.org/10.1257/aer.20171829},
   year = {2019},
}
@article{Ortoleva2012,
   abstract = {<p>Bayes' rule has two well-known limitations: 1) it does not model the reaction to zero-probability events; 2) a sizable empirical evidence documents systematic violations of it. We characterize axiomatically an alternative updating rule, the Hypothesis Testing model. According to it, the agent follows Bayes' rule if she receives information to which she assigned a probability above a threshold. Otherwise, she looks at a prior over priors, updates it using Bayes' rule for second-order priors, and chooses the prior to which the updated prior over priors assigns the highest likelihood. We also present an application to equilibrium refinement in game theory. (JEL D11, D81, D83)</p>},
   author = {Pietro Ortoleva},
   doi = {10.1257/aer.102.6.2410},
   issn = {0002-8282},
   issue = {6},
   journal = {American Economic Review},
   month = {10},
   pages = {2410-2436},
   title = {Modeling the Change of Paradigm: Non-Bayesian Reactions to Unexpected News},
   volume = {102},
   url = {https://pubs.aeaweb.org/doi/10.1257/aer.102.6.2410},
   year = {2012},
}
@article{Barron2021,
   abstract = {Bayes’ statistical rule remains the status quo for modeling belief updating in both normative and descriptive models of behavior under uncertainty. Some recent research has questioned the use of Bayes’ rule in descriptive models of behavior, presenting evidence that people overweight ‘good news’ relative to ‘bad news’ when updating ego-relevant beliefs. In this paper, we present experimental evidence testing whether this ‘good-news, bad-news’ effect is present in a financial decision making context (i.e. a domain that is important for understanding much economic decision making). We find no evidence of asymmetric updating in this domain. In contrast, in our experiment, belief updating is close to the Bayesian benchmark on average. However, we show that this average behavior masks substantial heterogeneity in individual updating behavior. We find no evidence in support of a sizeable subgroup of asymmetric updators.},
   author = {Kai Barron},
   doi = {10.1007/S10683-020-09653-Z/FIGURES/4},
   issn = {15736938},
   issue = {1},
   journal = {Experimental Economics},
   keywords = {Bayes’ rule,Belief measurement,Belief updating,Economic experiments,Motivated beliefs,Proper scoring rules},
   month = {3},
   pages = {31-58},
   publisher = {Springer},
   title = {Belief updating: does the ‘good-news, bad-news’ asymmetry extend to purely financial domains?},
   volume = {24},
   url = {https://link.springer.com/article/10.1007/s10683-020-09653-z},
   year = {2021},
}
@article{Coutts2019,
   abstract = {Bayesian updating remains the benchmark for dynamic modeling under uncertainty within economics. Recent theory and evidence suggest individuals may process information asymmetrically when it relates to personal characteristics or future life outcomes, with good news receiving more weight than bad news. I examine information processing across a broad set of contexts: (1) ego relevant, (2) financially relevant, and (3) non value relevant. In the first two cases, information about outcomes is valenced, containing either good or bad news. In the third case, information is value neutral. In contrast to a number of previous studies I do not find differences in belief updating across valenced and value neutral settings. Updating across all contexts is asymmetric and conservative: the former is influenced by sequences of signals received, a new variation of confirmation bias, while the latter is driven by non-updates. Despite this, posteriors are well approximated by those calculated using Bayes’ rule. Most importantly these patterns are present across all contexts, cautioning against the interpretation of asymmetric updating or other deviations from Bayes’ rule as being motivated by psychological biases.},
   author = {Alexander Coutts},
   doi = {10.1007/S10683-018-9572-5/TABLES/5},
   issn = {13864157},
   issue = {2},
   journal = {Experimental Economics},
   keywords = {Asymmetric belief updating,Bayes’ rule,Beliefs,Conservatism,Overconfidence},
   month = {6},
   pages = {369-395},
   publisher = {Springer New York LLC},
   title = {Good news and bad news are still news: experimental evidence on belief updating},
   volume = {22},
   url = {https://link.springer.com/article/10.1007/s10683-018-9572-5},
   year = {2019},
}
@unpublished{Ozyilmaz2022,
   author = {Hakan Ozyilmaz},
   title = {Mental Models and Endogenous Learning},
   url = {https://drive.google.com/file/d/1sNnaXye8p2bZ3Zzd36dYF0Dza47E26PG/view},
   year = {2022},
}
@article{Gotte2022,
   abstract = {This paper studies how people form beliefs in environments with multiple unknown parameters, some of which are relevant to agents' self-esteem. In particular, we examine how initial bias in beliefs about an ego-relevant characteristic affects learning about the state of the world. Using data from a laboratory experiment, we demonstrate that the learning process of an overconfident agent is self-defeating: the agent repeatedly takes suboptimal actions, misinterprets the output, and forms increasingly mistaken beliefs about the state. Therefore, we corroborate the theory of misguided learning formulated by Heidhues et al. (2018). We provide the first empirical evidence that allowing a biased agent to experiment and acquire new information is not only ineffective but in some cases counterproductive. Furthermore, we move beyond the theory as we examine how learning about multiple parameters evolves in ego-relevant and ego-neutral environments.},
   author = {Lorenz Götte and Marta Kozakiewicz},
   keywords = {D83,belief formation,experiment JEL classification: C91,learning,overconfidence},
   title = {Experimental Evidence on Misguided Learning},
   year = {2022},
}
@article{kelley1980,
   author = {Harold H Kelley and John L Michela},
   title = {ATTRIBUTION THEORY AND RESEARCH},
   url = {www.annualreviews.org},
   year = {1980},
}
@article{Nyarko1991,
   abstract = {I study the problem of a monopolist maximizing a sum of discounted profits facing a linear demand curve whose slope and intercept are unknown. I show that if the monopolist has a mis-specified model, i.e., if the true slope and intercept lie outside of the support of the monopolist's prior beliefs, then actions and beliefs may cycle on every sample path. This behavior is shown to be robust to perturbations in the prior, true parameter, and actions. Such behavior is not possible if the agent's model is correctly specified; instead actions and beliefs necessarily converge. © 1991.},
   author = {Yaw Nyarko},
   doi = {10.1016/0022-0531(91)90047-8},
   issn = {0022-0531},
   issue = {2},
   journal = {Journal of Economic Theory},
   month = {12},
   pages = {416-427},
   publisher = {Academic Press},
   title = {Learning in mis-specified models and the possibility of cycles},
   volume = {55},
   year = {1991},
}
@article{,
   abstract = {We model the dynamics of discrimination and show how its evolution can identify the underlying source. We test these theoretical predictions in a field experiment on a large online platform where users post content that is evaluated by other users on the platform. We assign posts to accounts that exogenously vary by gender and evaluation histories. With no prior evaluations, women face significant discrimination. However, following a sequence of positive evaluations, the direction of discrimination reverses: Women's posts are favored over men's. Interpreting these results through the lens of our model, this dynamic reversal implies discrimination driven by biased beliefs.},
   author = {By J Aislinn Bohren and Alex Imas and Michael Rosenberg and Nageeb Ali and Linda Babcock and Michael Callen and Hanming Fang and Uri Gneezy and Polina Imas and Nicola Gennaioli and Gregor Jarosch and Emir Kamenica and Gene Kucher and George Loewenstein and Kristof Madarasz and Craig McIntosh and Margaret Meyer and Siqi Pan and Sally Sadoff},
   doi = {10.1257/AER.20171829},
   issn = {0002-8282},
   issue = {10},
   journal = {American Economic Review},
   keywords = {Belief,Communication,Field Experiments, Search,Information and Knowledge,Learning,Non-labor Discrimination, Labor Discrimination,Unawareness, Economics of Gender},
   pages = {3395-3436},
   publisher = {American Economic Association},
   title = {The Dynamics of Discrimination: Theory and Evidence},
   volume = {109},
   url = {https://doi.org/10.1257/aer.20171829},
   year = {2019},
}
@misc{Spiegler2020,
   abstract = {This review presents an approach to modeling decision making under mis-specified subjective models. The approach is based on the idea that decision makers impose subjective causal interpretations on observed correlations, and it borrows basic concepts and tools from the statistics and artificial intelligence literatures on Bayesian networks. While these background litera-tures used Bayesian networks as a platform for normative and computational analysis of probabilistic and causal inference, in the framework proposed here graphical models represent causal misperceptions and help analyze their behavioral implications. I show how this approach sheds light on earlier equilibrium models with nonrational expectations and demonstrate its scope of economic applications.},
   author = {Ran Spiegler},
   doi = {10.1146/annurev-economics},
   keywords = {D90 Keywords Bayesian networks,JEL codes: D01,causal reasoning,directed acyclic graphs,misspecified models,nonrational expectations,personal equilibrium},
   title = {Behavioral Implications of Causal Misperceptions},
   url = {https://doi.org/10.1146/annurev-economics-},
   year = {2020},
}
@article{Huffman2022,
   abstract = {A long-standing puzzle is how overconfidence can persist in settings characterized by repeated feedback. This paper studies managers who participate repeatedly in a high-powered tournament incentive system, learning relative performance each time. Using reduced form and structural methods we find that (i) managers make overconfident predictions about future performance; (ii) managers have overly positive memories of past performance; (iii) the two phenomena are linked at an individual level. Our results are consistent with models of motivated beliefs in which individuals are motivated to distort memories of feedback and preserve unrealistic expectations.},
   author = {David Huffman and Collin Raymond and Julia Shvets and Sandro Ambuehl and Ned Augenblick and Heski Bar-Isaac and Doug Bernheim and Matias Cattaneo and Gary Charness and Armin Falk and Yoram Halevy and Paul Heidhues and P J Healy and Mitch Hoffman and Jun Ishii and Botond K˝ Oszegi and Yiming Liu and George Loewenstein and Ulrike Malmendier and Luis Santos-Pinto and Jean Tirole and Lise Vesterlund and Leeat Yariv and Florian Zimmermann},
   doi = {10.1257/AER.20190668},
   issn = {0002-8282},
   issue = {10},
   journal = {American Economic Review},
   keywords = {Asymmetric and Private Information,Belief,Communication,Information and Knowledge,Learning,Mechanism Design, Search,Payment Methods, Firm Performance: Size, Diversification, and Scope, Retail and Wholesale Trade,Unawareness, Compensation Packages},
   month = {10},
   pages = {3141-75},
   publisher = {American Economic Association},
   title = {Persistent Overconfidence and Biased Memory: Evidence from Managers},
   volume = {112},
   url = {https://doi.org/10.1257/aer.20190668},
   year = {2022},
}
@article{Barron2021,
   abstract = {Bayes’ statistical rule remains the status quo for modeling belief updating in both normative and descriptive models of behavior under uncertainty. Some recent research has questioned the use of Bayes’ rule in descriptive models of behavior, presenting evidence that people overweight ‘good news’ relative to ‘bad news’ when updating ego-relevant beliefs. In this paper, we present experimental evidence testing whether this ‘good-news, bad-news’ effect is present in a financial decision making context (i.e. a domain that is important for understanding much economic decision making). We find no evidence of asymmetric updating in this domain. In contrast, in our experiment, belief updating is close to the Bayesian benchmark on average. However, we show that this average behavior masks substantial heterogeneity in individual updating behavior. We find no evidence in support of a sizeable subgroup of asymmetric updators.},
   author = {Kai Barron},
   doi = {10.1007/S10683-020-09653-Z/FIGURES/4},
   issn = {15736938},
   issue = {1},
   journal = {Experimental Economics},
   keywords = {Bayes’ rule,Belief measurement,Belief updating,Economic experiments,Motivated beliefs,Proper scoring rules},
   month = {3},
   pages = {31-58},
   publisher = {Springer},
   title = {Belief updating: does the ‘good-news, bad-news’ asymmetry extend to purely financial domains?},
   volume = {24},
   url = {https://link.springer.com/article/10.1007/s10683-020-09653-z},
   year = {2021},
}
@article{Barber2002,
   abstract = {We analyze 1,607 investors who switched from phone-based to online trading during the 1990s. Those who switch to online trading perform well prior to going online, beating the market by more than 2% annually. After going online, they trade more actively, more speculatively, and less profitably than before - lagging the market by more than 3% annually. Reductions in market frictions (lower trading costs, improved execution speed, and greater ease of access) do not explain these findings. Overconfidence - augmented by self-attribution bias and the illusions of knowledge and control - can explain the increase in trading and reduction in performance of online investors.},
   author = {Brad M. Barber and Terrance Odean},
   doi = {10.1093/RFS/15.2.455},
   issn = {0893-9454},
   issue = {2},
   journal = {The Review of Financial Studies},
   month = {1},
   pages = {455-488},
   publisher = {Oxford Academic},
   title = {Online Investors: Do the Slow Die First?},
   volume = {15},
   url = {https://dx.doi.org/10.1093/rfs/15.2.455},
   year = {2002},
}
@article{Oster2013,
   abstract = {We use novel data to study genetic testing among individuals at risk for Huntington disease (HD), a hereditary disease with limited life expectancy. Although genetic testing is perfectly predictive and carries little economic cost, presymptomatic testing is rare. Testing rates increase with increases in ex ante risk of having HD. Untested individuals express optimistic beliefs about their health and make decisions (e.g., retirement) as if they do not have HD, even though individuals with confirmed HD behave differently. We suggest that these facts can be reconciled by an optimal expectations model (Brunnermeier and Parker 2005).},
   author = {Emily Oster and Ira Shoulson and E. Ray Dorsey},
   doi = {10.1257/AER.103.2.804},
   issn = {0002-8282},
   issue = {2},
   journal = {American Economic Review},
   keywords = {Expectations,Speculations, Health Production},
   month = {4},
   pages = {804-30},
   title = {Optimal Expectations and Limited Medical Testing: Evidence from Huntington Disease},
   volume = {103},
   year = {2013},
}
@article{Benoit2015,
   abstract = {We conduct two experimental tests of the claim that people are overconfident, using new tests of overplacement that are based on a formal Bayesian model. Our two experiments, on easy quizzes, find that people overplace themselves. More precisely, we find apparently overconfident data that cannot be accounted for by a rational population of expected utility maximizers who care only about money. The finding represents new evidence of overconfidence that is robust to the Bayesian critique offered by Benoît and Dubra (Jean-Pierre Benoît and Juan Dubra (2011). "Apparent Overconfidence." Econometrica, 79, 1591-1625). We discuss possible limitations of our results.},
   author = {Jean Pierre Benoît and Juan Dubra and Don A. Moore},
   doi = {10.1111/JEEA.12116},
   issn = {1542-4766},
   issue = {2},
   journal = {Journal of the European Economic Association},
   month = {4},
   pages = {293-329},
   publisher = {Oxford Academic},
   title = {Does the Better-than-Average Effect Show that People are Overconfident?: Two Experiments},
   volume = {13},
   url = {https://dx.doi.org/10.1111/jeea.12116},
   year = {2015},
}
@article{Hoffman2020,
   abstract = {<p>Combining weekly productivity data with weekly productivity beliefs for a large sample of truckers over 2 years, we show that workers tend to systematically and persistently overpredict their productivity. If workers are overconfident about their own productivity at the current firm relative to their outside option, they should be less likely to quit. Empirically, all else equal, having higher productivity beliefs is associated with an employee being less likely to quit. To study the implications of overconfidence for worker welfare and firm profits, we estimate a structural learning model with biased beliefs that accounts for many key features of the data. While worker overconfidence moderately decreases worker welfare, it also substantially increases firm profits.</p>},
   author = {Mitchell Hoffman and Stephen V. Burks},
   doi = {10.3982/QE834},
   issn = {1759-7323},
   issue = {1},
   journal = {Quantitative Economics},
   pages = {315-348},
   title = {Worker overconfidence: Field evidence and implications for employee turnover and firm profits},
   volume = {11},
   year = {2020},
}
@article{Camerer1999,
   author = {Colin Camerer and Dan Lovallo},
   doi = {10.1257/aer.89.1.306},
   issn = {0002-8282},
   issue = {1},
   journal = {American Economic Review},
   month = {3},
   pages = {306-318},
   title = {Overconfidence and Excess Entry: An Experimental Approach},
   volume = {89},
   year = {1999},
}
@article{Mezulis2004,
   author = {Amy H. Mezulis and Lyn Y. Abramson and Janet S. Hyde and Benjamin L. Hankin},
   doi = {10.1037/0033-2909.130.5.711},
   issn = {1939-1455},
   issue = {5},
   journal = {Psychological Bulletin},
   month = {9},
   pages = {711-747},
   title = {Is There a Universal Positivity Bias in Attributions? A Meta-Analytic Review of Individual, Developmental, and Cultural Differences in the Self-Serving Attributional Bias.},
   volume = {130},
   year = {2004},
}
@unpublished{Imas2022,
   abstract = {Click here to see the most recent version-Both over-and underreaction to information are well-documented empirically across a variety of domains. This paper explores how key features of the learning environment determine which bias emerges in a given setting. We first develop a two-stage model of belief formation. In the editing stage, limited attention leads the agent to use the representativeness heuristic to simplify the learning environment. In the evaluation stage, the agent forms subjective beliefs based on a noisy representation of the edited information structure. This model predicts underreaction when the state space is simple, signals are precise, and the prior is flat or diffuse; it predicts overreaction when the state space is complex, signals are noisy, and the prior is concentrated. A series of experiments provides direct support for these theoretical predictions. As a stark example, increasing the complexity of the state space from two to three states completely reverses the direction of the bias from underreaction to over-reaction. The results highlight that both stages of belief updating are crucial, in that neither stage on its own can explain the observed patterns in the data. Our framework also rationalizes the disparate findings in prior work: the model predicts the prevalence of underreaction in laboratory studies-which typically use a binary state space, relatively informative signals, and flat priors-as well as the predominance of overreaction documented in financial markets-which feature a more complex state space and noisier signals.},
   author = {Cuimin Ba and J. Aislinn Bohren and Alex Imas},
   doi = {10.2139/SSRN.4274617},
   journal = {SSRN Electronic Journal},
   keywords = {Alex Imas,Cuimin Ba,J. Aislinn Bohren,Over- and Underreaction to Information,SSRN,behavioral economics,beliefs,learning,noisy cognition,overreaction,representativeness,underreaction},
   month = {11},
   publisher = {Elsevier BV},
   title = {Over- and Underreaction to Information},
   url = {https://papers.ssrn.com/abstract=4274617},
   year = {2022},
}
@article{Bracha2012,
   abstract = {Optimism bias is inconsistent with the independence of decision weights and payoffs found in models of choice under risk and uncertainty, such as expected utility theory, subjective expected utility, and prospect theory. We therefore propose an alternative model of risky and uncertain choice where decision weights-affective or perceived risk-are endogenous.Affective decision making (ADM) is a strategic model of choice under risk and uncertainty where we posit two cognitive processes-the "rational" and the "emotional" process. The two processes interact in a simultaneous-move intrapersonal potential game, and observed choice is the result of a pure strategy Nash equilibrium in this game. We show that regular ADM potential games have an odd number of locally unique pure strategy Nash equilibria, and demonstrate this finding for affective decision making in insurance markets. We prove that ADM potential games are refutable by axiomatizing the ADM potential maximizers. © 2011 Elsevier Inc.},
   author = {Anat Bracha and Donald J. Brown},
   doi = {10.1016/J.GEB.2011.11.004},
   issn = {0899-8256},
   issue = {1},
   journal = {Games and Economic Behavior},
   keywords = {Affective expected utility,Demand for insurance,Optimism bias},
   month = {5},
   pages = {67-80},
   publisher = {Academic Press},
   title = {Affective decision making: A theory of optimism bias},
   volume = {75},
   year = {2012},
}
@article{Eil2011,
   abstract = {We study processing and acquisition of objective information regarding qualities that people care about, intelligence and beauty. Subjects receiving negative feedback did not respect the strength of these signals, were far less predictable in their updating behavior and exhibited an aversion to new information. In response to good news, inference conformed more closely to Bayes' Rule, both in accuracy and precision. Signal direction did not affect updating or acquisition in our neutral control. Unlike past work, our design varied direction and agreement with priors independently. The results indicate that confirmation bias is driven by direction; confirmation alone had no effect.},
   author = {David Eil and Justin M. Rao},
   doi = {10.1257/MIC.3.2.114},
   issn = {1945-7669},
   issue = {2},
   journal = {American Economic Journal: Microeconomics},
   keywords = {Asymmetric and Private Information, Search,Belief,Communication,Information and Knowledge,Learning},
   month = {5},
   pages = {114-38},
   title = {The Good News-Bad News Effect: Asymmetric Processing of Objective Information about Yourself},
   volume = {3},
   year = {2011},
}
@article{Bordalo2022,
   author = {Pedro Bordalo and Nicola Gennaioli and Andrei Shleifer},
   doi = {10.1257/JEP.36.3.223},
   issn = {0895-3309},
   issue = {3},
   journal = {Journal of Economic Perspectives},
   keywords = {Belief,Capacity,Communication,Cycles, Financial Markets and the Macroeconomy, Information and Market Efficiency,Event Studies,Fixed Investment and Inventory Studies,Information and Knowledge,Insider Trading, Capital Budgeting,Learning,Search,Speculations, General Aggregative Models: Neoclassical, Business Fluctuations,Unawareness, Expectations},
   month = {6},
   pages = {223-44},
   publisher = {American Economic Association},
   title = {Overreaction and Diagnostic Expectations in Macroeconomics},
   volume = {36},
   url = {https://doi.org/10.1257/jep.36.3.223.},
   year = {2022},
}
@article{Milgrom1981,
   abstract = {This is an article about modeling methods in information economics. A notion of "favorableness" of news is introduced, characterized, and applied to four simple models. In the equilibria of these models, (1) the arrival of good news about a firm's prospects always causes its share price to rise, (2) more favorable evidence about an agent's effort leads the principal to pay a larger bonus, (3) buyers expect that any product information withheld by a salesman is unfavorable to his product, and (4) bidders figure that low bids by their competitors signal a low value for the object being sold.},
   author = {Paul R. Milgrom},
   doi = {10.2307/3003562},
   issn = {0361915X},
   issue = {2},
   journal = {The Bell Journal of Economics},
   month = {23},
   pages = {380},
   publisher = {JSTOR},
   title = {Good News and Bad News: Representation Theorems and Applications},
   volume = {12},
   year = {1981},
}
@article{Schwarstein2021,
   abstract = {We present a framework where “model persuaders” influence receivers’ beliefs by proposing models that organize past data to make predictions. Receivers are assumed to find models more compelling when they better explain the data, fixing receivers’ prior beliefs. Model persuaders face a trade-off: better-fitting models induce less movement in receivers’ beliefs. Consequently, a receiver exposed to the true model can be most misled by persuasion when that model fits poorly, competition between persuaders tends to neutralize the data by pushing toward better-fitting models, and a persuader facing multiple receivers is more effective when he can send tailored, private messages.},
   author = {Joshua Schwartzstein and Adi Sunderam},
   doi = {10.1257/aer.20191074},
   issn = {19447981},
   issue = {1},
   journal = {American Economic Review},
   month = {1},
   pages = {276-323},
   publisher = {American Economic Association},
   title = {Using models to persuade},
   volume = {111},
   year = {2021},
}
@article{Bordalo2016,
   abstract = {We present a model of stereotypes based on Kahneman and Tversky's representativeness heuristic. A decision maker assesses a target group by overweighting its representative types, defined as the types that occur more frequently in that group than in a baseline reference group. Stereotypes formed this way contain a ''kernel of truth'': they are rooted in true differences between groups. Because stereotypes focus on differences, they cause belief distortions, particularly when groups are similar. Stereotypes are also context dependent: beliefs about a group depend on the characteristics of the reference group. In line with our predictions, beliefs in the lab about abstract groups and beliefs in the field about political groups are context dependent and distorted in the direction of representative types. JEL Codes: D03, D83, D84, C91.},
   author = {Pedro Bordalo and Katherine Coffman and Nicola Gennaioli and Andrei Shleifer},
   doi = {10.1093/qje/qjw029},
   issn = {15314650},
   issue = {4},
   journal = {Quarterly Journal of Economics},
   month = {11},
   pages = {1753-1794},
   publisher = {Oxford University Press},
   title = {Stereotypes},
   volume = {131},
   year = {2016},
}
@article{Fudenberg2017,
   abstract = {Copyright © 2017 The Authors. We study learning and information acquisition by a Bayesian agent whose prior belief is misspecified in the sense that it assigns probability 0 to the true state of the world. At each instant, the agent takes an action and observes the corresponding payoff, which is the sum of a fixed but unknown function of the action and an additive error term. We provide a complete characterization of asymptotic actions and beliefs when the agent's subjective state space is a doubleton. A simple example with three actions shows that in a misspecified environment a myopic agent's beliefs converge while a sufficiently patient agent's beliefs do not. This illustrates a novel interaction between misspecification and the agent's subjective discount rate.},
   author = {Drew Fudenberg and Gleb Romanyuk and Philipp Strack},
   doi = {10.3982/te2480},
   issn = {15557561},
   issue = {3},
   journal = {Theoretical Economics},
   month = {9},
   pages = {1155-1189},
   publisher = {The Econometric Society},
   title = {Active learning with a misspecified prior},
   volume = {12},
   year = {2017},
}
@article{Levy2022,
   abstract = {We develop a dynamic model of political competition between two groups that differ in their subjective model of the data generating process for a common outcome. One group has a simpler model than the other group as they ignore some relevant policy variables. We show that policy cycles must arise and that simple world views—which can be interpreted as populist world views—imply extreme policy choices. Periods in which those with a more complex model govern increase the specification error of the simpler world view, leading the latter to overestimate the positive impact of a few extreme policy actions.},
   author = {Gilat Levy and Ronny Razin and Alwyn Young},
   doi = {10.1257/AER.20210154},
   issn = {19447981},
   issue = {3},
   journal = {American Economic Review},
   month = {3},
   pages = {928-962},
   publisher = {American Economic Association},
   title = {Misspecified Politics and the Recurrence of Populism},
   volume = {112},
   year = {2022},
}
@article{Hestermann2021,
   abstract = {We study an experimentation problem in a situation where the outcomes depend on the decision-maker’s intrinsic ability and on an external variable. We analyze the mistakes made by individuals who hold inaccurate prior beliefs about their ability. Overconfident individuals take too much credit for their successes and excessively blame external factors if they fail. They are too easily dissatisfied with their environment, which leads them to experiment in variable environments and revise their self-confidence over time. In contrast, underconfident individuals might be trapped in low-quality environments and incur perpetual utility losses. (JEL D11, D83, D91)},
   author = {Nina Hestermann and Yves Le Yaouanq},
   doi = {10.1257/mic.20180326},
   issn = {19457685},
   issue = {3},
   journal = {American Economic Journal: Microeconomics},
   pages = {198-237},
   publisher = {American Economic Association},
   title = {Experimentation with Self-Serving Attribution Biases},
   volume = {13},
   year = {2021},
}
@unpublished{Coffman2021,
   abstract = {We explore how feedback shapes, and perpetuates, gender gaps in self-assessments. Participants in our experiments take tests of their ability across different domains. We elicit their beliefs of their performance before and after feedback. We find that, even after the provision of highly informative feedback, gender stereotypes influence posterior beliefs, beyond what a Bayesian model would predict. This is primarily because both men and women update their beliefs more positively in response to good news when it arrives in a more gender congruent domain (i.e., more male-typed domains for men, more female-typed domains for women), fueling persistence in gender gaps.},
   author = {Katherine Coffman and Manuela Collis and Leena Kulkarni and Lucas Coffman and P J Healy and Alex Imas and Muriel Niederle and Matthew Rabin and Andrei Shleifer and Joshua Schwartzstein and Charles Sprenger and Lise Vesterlund},
   title = {Stereotypes and Belief Updating},
   year = {2021},
}
@inbook{Benjamin2019,
   abstract = {Errors in probabilistic reasoning have been the focus of much psychology research and are among the original topics of modern behavioral economics. This chapter reviews theory and evidence on this topic, with the goal of facilitating more systematic study of belief biases and their integration into economics. The chapter discusses biases in beliefs about random processes, biases in belief updating, the representativeness heuristic as a possible unifying theory, and interactions between biased belief updating and other features of the updating situation. Throughout, I aim to convey how much evidence there is for (and against) each putative bias, and I highlight when and how different biases may be related to each other. The chapter ends by drawing general lessons for when people update too much or too little, reflecting on modeling challenges, pointing to areas of economics to which the biases are relevant, and highlighting some possible directions for future work.},
   author = {Daniel J. Benjamin},
   doi = {10.1016/bs.hesbe.2018.11.002},
   pages = {69-186},
   title = {Errors in probabilistic reasoning and judgment biases},
   year = {2019},
}
@article{Esponda2023,
   abstract = {Using a laboratory experiment, we investigate the extent to which learning is transferred between related problems in the context of an updating task. The updating principle we study requires updating positively after a positive signal and negatively after a negative signal. In the first environment, most subjects initially fail to satisfy the principle but eventually adjust after feedback. The environment they face subsequently presents the same challenges but with different parameter values. We find weak evidence for transfer learning: only half of the subjects who learn to be consistent with the principle remain so when the parameter values are changed.},
   author = {Ignacio Esponda and Emanuel Vespa and Sevgi Yuksel},
   doi = {10.1257/pandp.20231114},
   issn = {2574-0768},
   journal = {AEA Papers and Proceedings},
   month = {5},
   pages = {659-664},
   publisher = {American Economic Association},
   title = {Mental Models and Transfer Learning},
   volume = {113},
   year = {2023},
}
@article{Heidhues2018,
   abstract = {We explore the learning process and behavior of an individual with unrealistically high expectations (overconfidence) when outcomes also depend on an external fundamental that affects the optimal action. Moving beyond existing results in the literature, we show that the agent's beliefs regarding the fundamental converge under weak conditions. Furthermore, we identify a broad class of situations in which "learning" about the fundamental is self-defeating: it leads the individual systematically away from the correct belief and toward lower performance. Due to his overconfidence, the agent-even if initially correct-becomes too pessimistic about the fundamental. As he adjusts his behavior in response, he lowers outcomes and hence becomes even more pessimistic about the fundamental, perpetuating the misdirected learning. The greater is the loss from choosing a suboptimal action, the further the agent's action ends up from optimal. We partially characterize environments in which self-defeating learning occurs, and show that the decisionmaker learns to take the optimal action if, and in a sense only if, a specific non-identifiability condition is satisfied. In contrast to an overconfident agent, an underconfident agent's misdirected learning is self-limiting and therefore not very harmful. We argue that the decision situations in question are common in economic settings, including delegation, organizational, effort, and public-policy choices.},
   author = {Paul Heidhues and Botond Kőszegi and Philipp Strack},
   doi = {10.3982/ecta14084},
   issn = {0012-9682},
   issue = {4},
   journal = {Econometrica},
   pages = {1159-1214},
   publisher = {The Econometric Society},
   title = {Unrealistic Expectations and Misguided Learning},
   volume = {86},
   year = {2018},
}
@article{Bohren2021,
   abstract = {This paper develops a general framework to study how misinterpreting information impacts learning. Our main result is a simple criterion to characterize long‐run beliefs based on the underlying form of misspecification. We present this characterization in the context of social learning, then highlight how it applies to other learning environments, including individual learning. A key contribution is that our characterization applies to settings with model heterogeneity and provides conditions for entrenched disagreement. Our characterization can be used to determine whether a representative agent approach is valid in the face of heterogeneity, study how differing levels of bias or unawareness of others' biases impact learning, and explore whether the impact of a bias is sensitive to parametric specification or the source of information. This unified framework synthesizes insights gleaned from previously studied forms of misspecification and provides novel insights in specific applications, as we demonstrate in settings with partisan bias, overreaction, naive learning, and level‐k reasoning.},
   author = {J. Aislinn Bohren and Daniel N. Hauser},
   doi = {10.3982/ecta15318},
   issn = {0012-9682},
   issue = {6},
   journal = {Econometrica},
   pages = {3025-3077},
   publisher = {The Econometric Society},
   title = {Learning With Heterogeneous Misspecified Models: Characterization and Robustness},
   volume = {89},
   year = {2021},
}
@article{Esponda2016,
   abstract = {We develop an equilibrium framework that relaxes the standard assumption that people have a correctly-specified view of their environment. Each player is characterized by a (possibly misspecified) subjective model, which describes the set of feasible beliefs over payoff-relevant consequences as a function of actions. We introduce the notion of a Berk-Nash equilibrium: Each player follows a strategy that is optimal given her belief, and her belief is restricted to be the best fit among the set of beliefs she considers possible. The notion of best fit is formalized in terms of minimizing the Kullback-Leibler divergence, which is endogenous and depends on the equilibrium strategy profile. Standard solution concepts such as Nash equilibrium and self-confirming equilibrium constitute special cases where players have correctly-specified models. We provide a learning foundation for Berk-Nash equilibrium by extending and combining results from the statistics literature on misspecified learning and the economics literature on learning in games.},
   author = {Ignacio Esponda and Demian Pouzo},
   doi = {10.3982/ecta12609},
   issn = {0012-9682},
   issue = {3},
   journal = {Econometrica},
   pages = {1093-1130},
   publisher = {The Econometric Society},
   title = {Berk-Nash Equilibrium: A Framework for Modeling Agents With Misspecified Models},
   volume = {84},
   year = {2016},
}
@unpublished{,
   abstract = {We link two approaches to biased belief formation: non-Bayesian updating rules and model misspecification. Each approach has advantages: updating rules transparently capture the underlying bias and are identifiable from belief data; misspecified models are 'complete' and amenable to general analysis. We show that misspecified models can be decomposed into an updating rule and forecast of anticipated future beliefs. We derive necessary and sufficient conditions for an updating rule and forecast to have a misspecified model representation, show the representation is unique, and construct it. This highlights the belief restrictions implicit in the misspecified model approach. Finally, we explore two ways to select forecasts-introspection-proof and naive consistent-and derive when a representation of each exists. Kevin He, Ryota Iijima, Alex Imas, Jawaad Noor and seminar and conference participants at various institutions for helpful comments and suggestions. Cuimin Ba and Marcus Tomaino provided excellent research assistance. Bohren gratefully acknowledges financial support from NSF grant SES-1851629.},
   author = {J Aislinn Bohren and Daniel N Hauser and Nageeb Ali and Cuimin Ba and Renee Bowen and Sylvain Chassang and Hanming Fang and Mira Frick},
   keywords = {Model misspecification,belief formation,heuristics * We thank,learning,non-Bayesian updating},
   title = {Behavioral Foundations of Model Misspecification *},
   year = {2023},
}
@article{Yariv2005,
   abstract = {Many observations from psychology, political science, and organizational behavior indicate that people exhibit a taste for consistency. Individuals are inclined to interpret new evidence in ways that con…rm their pre-existing beliefs. They also tend to change their beliefs to enhance the desirability of their past actions. The current paper explores the implications of a simple model incorporating these e¤ects into an agent's utility function. The model allows a characterization of when: 1. agents become under-and over-con…dent, 2. agents prefer less accurate signals, i.e., they are willing to pay in order to forgo information, and 3. agents exhibit excess stickiness or excess volatility in action choices. am grateful to the Alfred P. Sloan foundation and the Eliot committee for generous …nancial support.},
   author = {Leeat Yariv and Alberto Alesina and Itzhak Gilboa and Ed Glaeser and Orit Kedar and David Levine and Ted Miguel and Paul Milgrom and Markus Mobius and Al Roth and Michael Schwarz and Steve I Tadelis},
   journal = {working paper},
   keywords = {Belief utility,cognitive dissonance,con…rmatory bias,overcon…-dence,selective exposure},
   title = {I'll See It When I Believe It-A Simple Model of Cognitive Consistency},
   year = {2005},
}
@misc{Bordalo2019,
   abstract = {We conduct laboratory experiments that explore how gender stereotypes shape beliefs about ability of oneself and others in different categories of knowledge. The data reveal two patterns. First, men’s and women’s beliefs about both oneself and others exceed observed ability on average, particularly in difficult tasks. Second, overestimation of ability by both men and women varies across categories. To understand these patterns, we develop a model that separates gender stereotypes from misestimation of ability related to the difficulty of the task. We find that stereotypes contribute to gender gaps in self-confidence, assessments of others, and behavior in a cooperative game. (JEL C92, D83, D91, J16).},
   author = {Pedro Bordalo and Katherine Coffman and Nicola Gennaioli and Andrei Shleifer},
   doi = {10.1257/aer.20170007},
   issn = {19447981},
   issue = {3},
   journal = {American Economic Review},
   month = {3},
   pages = {739-773},
   publisher = {American Economic Association},
   title = {Beliefs about gender},
   volume = {109},
   year = {2019},
}
@unpublished{Ba2023,
   abstract = {Individuals use models to guide decisions, but many models are wrong. This paper studies which misspecified models are likely to persist when individuals also entertain alternative models. Consider an agent who uses her model to learn the relationship between action choices and outcomes. The agent exhibits sticky model switching, captured by a threshold rule such that she switches to an alternative model when it is a sufficiently better fit for the data she observes. The main result provides a characterization of whether a model persists based on two key features that are straightforward to derive from the primitives of the learning environment, namely, the model's asymptotic accuracy in predicting the equilibrium pattern of observed outcomes and the 'tightness' of the prior around this equilibrium. I show that misspecified models can be robust in that they persist against a wide range of competing models-including the correct model-despite individuals observing an infinite amount of data. Moreover, simple misspecified models with entrenched priors can be even more robust than correctly specified models. I use this characterization to provide a learning foundation for the persistence of systemic biases in two applications. First, in an effort-choice problem, I show that overconfidence in one's ability is more robust than underconfidence. Second, a simplistic binary view of politics is more robust than the more complex correct view when individuals consume media without fully recognizing the reporting bias.},
   author = {Cuimin Ba},
   title = {Robust Misspecified Models and Paradigm Shifts},
   year = {2023},
}
@article{Brunnermeier2005,
   abstract = {Forward-looking agents care about expected future utility flows, and hence have higher current felicity if they are optimistic. This paper studies utility-based biases in beliefs by supposing that beliefs maximize average felicity, optimally balancing this benefit of optimism against the costs of worse decision making. A small optimistic bias in beliefs typically leads to first-order gains in anticipatory utility and only second-order costs in realized outcomes. In a portfolio choice example, investors overestimate their return and exhibit a preference for skewness; in general equilibrium, investors' prior beliefs are endogenously heterogeneous. In a consumption saving example, consumers are both overconfident and overoptimistic. (JEL D1, D8, E21, G11, G12) Modern psychology views human behavior as a complex interaction of cognitive and emotional responses to external stimuli that sometimes results in dysfunctional outcomes. Modern economics takes a relatively simple view of human behavior as governed by unlimited cognitive ability applied to a small number of concrete goals and unencumbered by emotion. The central models of economics allow coherent analysis of behavior and economic policy, but eliminate "dysfunctional" outcomes, and in particular the possibility that individuals might persistently err in attaining their goals. One area in which there is substantial evidence that individuals do consistently err is in the assessment of probabilities. In particular, agents often overestimate the probability of good outcomes , such as their success (Marc Alpert and Howard Raiffa, 1982; Neil D. Weinstein, 1980; and Roger Buehler et al., 1994). We provide a structural model of subjective beliefs in which agents hold incorrect but optimal beliefs. These optimal beliefs differ from objective beliefs in ways that match many of the claims in the psychology literature about "irra-tional" behavior. Further, in the canonical economic models that we study, these beliefs lead to economic behaviors that match observed outcomes that have puzzled the economics literature based on rational behavior and common priors. Our approach has three main elements. First, at any instant people care about current utility flow and expected future utility flows. While it is standard that agents who care about expected future utility plan for the future, forward-looking agents have higher current felicity if they are optimistic about the future. For example , agents who care about expected future util},
   author = {Markus K Brunnermeier and Jonathan A Parker},
   issue = {4},
   journal = {The American Economic Review},
   pages = {1092-1118},
   title = {Optimal Expectations},
   volume = {95},
   year = {2005},
}
@unpublished{Coutts2020,
   abstract = {People often receive feedback that depends on factors beyond their ability, yet little is known about how this alters the scope for self-serving biases. In a theory-guided experiment, individuals receive a noisy signal about their ability, which comes bundled with another source of uncertainty-a teammate's ability. In this environment individuals can attribute the feedback across these two dimensions, updating in a self-serving fashion, leveraging the additional flexibility from multi-dimensional uncertainty. In the experiment, rather than blaming their teammate, they process information about them in a positively biased way. This reduces costs associated with over-attribution towards own performance, but later impedes learning by decreasing willingness to change teammates. These results suggest that individuals distort their perceptions of the environment in order to arrive at self-serving beliefs.},
   author = {Alexander Coutts and Leonie Gerhards and Zahra Murad},
   title = {What to blame? Self-serving attribution bias with multi-dimensional uncertainty},
   year = {2020},
}
@article{Mobius2022,
   abstract = {<p>We use a series of experiments to understand whether and how people’s beliefs about their own abilities are biased relative to the Bayesian benchmark and how these beliefs then affect behavior. We find that subjects systematically and substantially overweight positive feedback relative to negative (asymmetry) and also update too little overall (conservatism). These biases are substantially less pronounced in an ego-free control experiment. Updating does retain enough of the structure of Bayes’ rule to let us model it coherently in an optimizing framework, in which, interestingly, asymmetry and conservatism emerge as complementary biases. We also find that exogenous changes in beliefs affect subjects’ decisions to enter into a competition and do so similarly for more and less biased subjects, suggesting that people cannot “undo” their biases when the time comes to decide.</p>},
   author = {Markus M. Möbius and Muriel Niederle and Paul Niehaus and Tanya S. Rosenblat},
   doi = {10.1287/mnsc.2021.4294},
   issn = {0025-1909},
   issue = {11},
   journal = {Management Science},
   keywords = {asymmetric belief updating,conservatism,information aversion},
   month = {11},
   pages = {7793-7817},
   title = {Managing Self-Confidence: Theory and Experimental Evidence},
   volume = {68},
   url = {https://pubsonline.informs.org/doi/10.1287/mnsc.2021.4294},
   year = {2022},
}
@misc{Zimmermann2020,
   abstract = {A key question in the literature on motivated reasoning and self-deception is how motivated beliefs are sustained in the presence of feedback. In this paper, we explore dynamic motivated belief patterns after feedback. We establish that positive feedback has a persistent effect on beliefs. Negative feedback, instead, influences beliefs in the short run, but this effect fades over time. We investigate the mechanisms of this dynamic pattern, and provide evidence for an asymmetry in the recall of feedback. Finally, we establish that, in line with theoretical accounts, incentives for belief accuracy mitigate the role of motivated reasoning.},
   author = {Florian Zimmermann},
   doi = {10.1257/aer.20180728},
   issn = {19447981},
   issue = {2},
   journal = {American Economic Review},
   pages = {337-363},
   publisher = {American Economic Association},
   title = {The dynamics of motivated beliefs},
   volume = {110},
   year = {2020},
}
@article{otree,
   abstract = {oTree is an open-source and online software for implementing interactive experiments in the laboratory, online, the field or combinations thereof. oTree does not require installation of software on subjects' devices; it can run on any device that has a web browser, be that a desktop computer, a tablet or a smartphone. Deployment can be internet-based without a shared local network, or local-network-based even without internet access. For coding, Python is used, a popular, open-source programming language. www.oTree.org provides the source code, a library of standard game templates and demo games which can be played by anyone.},
   author = {Daniel L. Chen and Martin Schonger and Chris Wickens},
   doi = {10.1016/j.jbef.2015.12.001},
   issn = {22146350},
   journal = {Journal of Behavioral and Experimental Finance},
   keywords = {Classroom experiments,Experimental economics,Field experiments,Laboratory experiments,Online experiments,Software},
   month = {3},
   pages = {88-97},
   publisher = {Elsevier},
   title = {oTree—An open-source platform for laboratory, online, and field experiments},
   volume = {9},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S2214635016000101},
   year = {2016},
}
@book{Savage1972,
   author = {Leonard J. Savage},
   publisher = {Wiley Publications in Statistics},
   title = {The Foundations of Statistics},
   year = {1972},
}
@article{Haghtalab2021,
   author = {Nika Haghtalab and Matthew O. Jackson and Ariel D. Procaccia},
   issue = {19},
   journal = {PNAS},
   title = {Belief polarization in a complex world: A learning theory perspective},
   volume = {118},
   year = {2021},
}

@article{Augenblick2021,
   abstract = {When a Bayesian learns new information and changes her beliefs, she must on average become concomitantly more certain about the state of the world. Consequently, it is rare for a Bayesian to frequently shift beliefs substantially while remaining relatively uncertain, or, conversely, become very confident with relatively little belief movement. We formalize this intuition by developing specific measures of movement and uncertainty reduction given a Bayesian's changing beliefs over time, showing that these measures are equal in expectation and creating consequent statistical tests for Bayesianess. We then show connections between these two core concepts and four common psychological biases, suggesting that the test might be particularly good at detecting these biases. We provide support for this conclusion by simulating the performance of our test and other martingale tests. Finally, we apply our test to data sets of individual, algorithmic, and market beliefs.},
   author = {Ned Augenblick and Matthew Rabin},
   doi = {10.1093/qje/qjaa043},
   issn = {15314650},
   issue = {2},
   journal = {Quarterly Journal of Economics},
   month = {5},
   note = {Bayesian updating is characterized by reduction in uncertainty after the update},
   pages = {933-985},
   publisher = {Oxford University Press},
   title = {Belief movement, uncertainty reduction, and rational updating},
   volume = {136},
   year = {2021},
}
@article{Mailath2020,
   abstract = {People reason about uncertainty with deliberately incomplete models. How do people hampered by different, incomplete views of the world learn from each other? We introduce a model of “model-based inference.” Model-based reasoners partition an otherwise hopelessly complex state space into a manageable model. Unless the differences in agents’models are trivial, interactions will often not lead agents to have common beliefs or beliefs near the correct-model belief. If the agents’models have enough in common, then interacting will lead agents to similar beliefs, even if their models also exhibit some bizarre idiosyncrasies and their information is widely dispersed.},
   author = {George J. Mailath and Larry Samuelson},
   doi = {10.1257/aer.20190080},
   issn = {19447981},
   issue = {5},
   journal = {American Economic Review},
   month = {5},
   note = {model-based inference with incomplete models. Partition the state space into a more manageable model. Unless the differences in agents’ models are trivial, interactions will<br/>often not lead agents to have common beliefs or beliefs near the<br/>correct-model belief.<br/>THEY RESPOND TO THE BELIEFS OF OTHERS},
   pages = {1461-1501},
   publisher = {American Economic Association},
   title = {Learning under diverse world views: Model-based inference†},
   volume = {110},
   year = {2020},
}
@article{Esponda2021,
   abstract = {We consider an agent who represents uncertainty about the environment via a possibly misspecified model. Each period, the agent takes an action, observes a consequence, and uses Bayes' rule to update her belief about the environment. This framework has become increasingly popular in economics to study behavior driven by incorrect or biased beliefs. By first showing that the key element to predict the agent's behavior is the frequency of her past actions, we are able to characterize asymptotic behavior in general settings in terms of the solutions of a differential inclusion that describes the evolution of the frequency of actions. We then present a series of implications that can be readily applied to economic applications, thus providing off-the-shelf tools that can be used to characterize behavior under misspecified learning.},
   author = {Ignacio Esponda and Demian Pouzo and Yuichi Yamamoto},
   doi = {10.1016/j.jet.2021.105260},
   issn = {10957235},
   journal = {Journal of Economic Theory},
   keywords = {Asymptotic behavior,Bayesian learning,Berk-Nash equilibrium,Differential inclusion,Misspecified models},
   month = {7},
   note = {the agent takes an action, sees a consequence and updates their belief. Implications that characterize behavior:<br/>cyclic behavior,  misdirected learning as in HKS's overconfidence model.<br/><br/>REFERENCES OF MISSPECIFIED LEARNING},
   publisher = {Academic Press Inc.},
   title = {Asymptotic behavior of Bayesian learners with misspecified models},
   volume = {195},
   year = {2021},
}
@misc{,
   abstract = {We develop a framework for assessing when a person will notice that a theory she has about the world is wrong, premised on the idea that people neglect information that they view (through the lens of their misconceptions) to be irrelevant. Focusing on the question of when a mistaken theory can persist in the long run even when attention is very cheap, we study the attentional stability of both general psychological biases-such as naivete about present bias or neglecting the redundancy in social information-and context-specific empirical misconceptions-such as false beliefs about medicinal side effects or financial investments. People discover their errors only when the data they deem relevant causes them to incidentally notice that their theory is wrong. We explore which combinations of errors and environments allow an error to persist. People tend to notice costly errors in a particular context when they are right about which factors matter even when they are wrong about how these factors matter, whereas errors that lead people to ubiquitously treat consequential factors as irrelevant will be stable across a broad class of environments. Environments designed to make such factors artificially germane can induce recognition of an error.},
   author = {Tristan Gagnon-Bartsch and Harvard Matthew and Rabin Harvard and Joshua Schwartzstein and Nava Ashraf and Francesca Bastianello and Max Bazerman and Katherine Coffman and Christine Exley and Erik Eyster and Drew Fudenberg and Nicola Gennaioli and Brian Hall and David Hirshleifer and Botond K˝ Oszegi and Spencer Kwon and George Loewenstein and Michael Luca and Kathleen Mcginn and Sendhil Mullainathan and Andrei Shleifer and Dmitry Taubinsky and Yale Gagnon-Bartsch and Rabin Thank},
   title = {Channeled Attention and Stable Errors},
   year = {2021},
}
@misc{,
   abstract = {An important issue in decision making concerns the manner in which people process new information and update prior beliefs. The Bayesian updating rule, in combination with expected utility theory, is ubiquitous in economic theory, and its application is an important paradigm for examining decision making under risk. A number of experimental studies suggest, however, that people may often ignore prior information when forming beliefs, contrary to Bayes's rule. 1 Another heuristic for processing new information involves some form of reinforcement , where one is more likely to pick choices (actions) associated with successful past outcomes than choices associated with less successful outcomes. 2 These separate approaches often prescribe a similar course of action in the face of new information; however, this is not always the case. We construct an individual choice task in which Bayesian updating with expected utility maximization (BEU) sometimes coincides and sometimes opposes a "win-stay lose-shift" heu-ristic. Here, Bayesian updating after a successful outcome should lead a decision maker to make a change, while no change should be made after observing an unsuccessful outcome. We observe how one's propensity to use Bayes's rule is affected by whether this rule is aligned with the win-stay lose-shift heuristic or clashes with it. We also consider whether this propensity differs according to whether the information provided by an earlier outcome is accompanied by payment for the outcome and the corresponding feelings of success or failure. To the best of our knowledge, this is the first study to examine explicitly what happens when these forces work against one another. 3 Our constructed case where the reinforcement heu-ristic leads one astray can be applied more generally to situations where favorable direct). We thank Mark Brinkman and Arun Qamra for their help with designing the software and conducting the experimental sessions. We thank Doug Bernheim and an anonymous referee for valuable editorial comments. We have benefited from discussions with, and suggestions from, also provide strong evidence that experimental subjects are often not even close to being "perfect Bayesians." 2 The basic reinforcement learning models (e.g., Alvin E. Roth and Ido Erev, 1995; Erev and Roth, 1998) assume an initial propensity for a particular choice and utilize a payoff sensitivity parameter. Colin Camerer and Teck-Hua Ho (1998, 1999) combine reinforcement and belief learning by using experience-weights and updated levels of attraction. Case-based decision theory (Gilboa and Schmeidler, 1995, 2001) formalizes the thrust of reinforcement heuristics in a nonexpected utility framework wherein people follow a decision rule that chooses an act with the highest relative score, based on performance in past cases and the similarity of those cases to the current decision case. 3 Note that our setup is quite different from the "two-armed bandit" problem, where the separate machines have independent distributions rather than a common state. 1300},
   author = {By Gary Charness and Dan Levin and George Akerlof and Ted Bergstrom and Antonio Cabrales and James Choi and Carl Christ and Stefano DellaVigna and Matthew Ellman and Ido Erev and Guillaume Fréchette and Rod Gar-ratt and Itzhak Gilboa and Robin Hogarth and Edi Karni and Botond Koz-segi and David Laibson and Cade Massey and Jim Peck and Matthew Rabin and David Schmeidler and Bill Zame and Richard Zeckhauser},
   publisher = {Kahneman and Tversky},
   title = {When Optimal Choices Feel Wrong: A Laboratory Study of Bayesian Updating, Complexity, and Affect},
   url = {www.econ.ucsb.edu/gcsurvey/Bayesian_updating/.},
   year = {1971},
}
@article{Liang2020,
   abstract = {We develop a model of social learning from complementary information: short-lived agents sequentially choose from a large set of flexibly correlated information sources for prediction of an unknown state, and information is passed down across periods. Will the community collectively acquire the best kinds of information? Long-run outcomes fall into one of two cases: (i) efficient information aggregation, where the community eventually learns as fast as possible; (ii) "learning traps," where the community gets stuck observing suboptimal sources and information aggregation is inefficient. Our main results identify a simple property of the underlying informational complementarities that determines which occurs. In both regimes, we characterize which sources are observed in the long run and how often.},
   author = {Annie Liang and Xiaosheng Mu},
   doi = {10.1093/qje/qjz033},
   issn = {15314650},
   issue = {1},
   journal = {Quarterly Journal of Economics},
   month = {2},
   pages = {389-448},
   publisher = {Oxford University Press},
   title = {Complementary Information and Learning Traps},
   volume = {135},
   year = {2020},
}
@misc{Epstein2008,
   abstract = {This paper models an agent in a multi-period setting who does not update according to Bayes' Rule, and who is self-aware and anticipates her updating behavior when formulating plans. Choice-theoretic axiomatic foundations are provided to capture updating biases that reflect excessive weight given to either prior beliefs, or, alternatively, to observed data. A counterpart of the exchangeable Bayesian learning model is also described. K. Non-Bayesian updating, temptation and self-control, overreaction, underreaction, learning, law of small numbers. JEL . D81. 1. I Epstein (2006) models an agent who does not update according to Bayes' Rule, but is self-aware and anticipates her updating behavior when formulating plans. He provides axiomatic foundations for his model in the form of a representation theorem for suitably defined preferences such that both the prior and the way in which it is updated are subjective. The model is nested in a three-period framework, where the agent updates once and consumption occurs only at the terminal time. This paper extends the model to an infinite horizon setting, thereby enabling it to address dynamic issues and making it more amenable to applications. The benchmark for the present model is the standard specification of utility in dynamic modeling, whereby utility at time t is given by U t (c) = E t ∞ τ=t δ τ−t u (c τ) t = 0, 1,. .. ,},
   author = {Larry G Epstein and Alvaro Sandroni and Massimo Marinacci and Joseph Perktold and Werner Ploberger and especially Igor Kopylov},
   journal = {Theoretical Economics},
   pages = {193-229},
   title = {Non-Bayesian updating: a theoretical framework We have benefitted from comments from two referees and an editor, and from conversations with Mark},
   volume = {3},
   url = {http://econtheory.org.},
   year = {2008},
}
@article{Schwartzstein2014,
   abstract = {What do we notice and how does this affect what we learn and come to believe? I present a model of an agent who learns to make forecasts on the basis of readily available information, but is selective as to which information he attends to: he chooses whether to attend as a function of current beliefs about whether such information is predictive. If the agent does not attend to some piece of information, it cannot be recalled at a later date. He uses Bayes' rule to update his beliefs given attended-to information, but does not attempt to fill in missing information. The model demonstrates how selective attention may lead the agent to persistently fail to recognize important empirical regularities, make systematically biased forecasts, and hold incorrect beliefs about the statistical relationship between variables. In addition, it identifies factors that make such errors more likely or persistent. The model is applied to shed light on stereotyping and discrimination, persistent learning failures and disagreement, and the process of discovery.},
   author = {Joshua Schwartzstein},
   doi = {10.1111/jeea.12104},
   issn = {15424774},
   issue = {6},
   journal = {Journal of the European Economic Association},
   month = {12},
   pages = {1423-1452},
   publisher = {Wiley-Blackwell},
   title = {Selective attention and learning},
   volume = {12},
   year = {2014},
}
@misc{Acemoglu2006,
   abstract = {Most economic analyses presume that there are limited differences in the beliefs ("priors") of individuals, an assumption most often justified by the argument that sufficient common experiences and observations will eliminate disagreements. We investigate this claim using a simple model of learning. Two individuals with different priors observe the same infinite sequence of signals about some underlying parameter. Existing results in the literature establish that when individuals are certain about the interpretation of signals, under very mild conditions their assessments will eventually agree. In contrast, we look at an environment in which individuals are uncertain about the interpretation of signals, meaning that they also have non-degenerate probability distributions over the likelihood of signals given the underlying parameter. Assuming that the priors (about the parameter and the conditional distribution of the signals) have full support, we prove the following results. (1) Individuals will never agree, even after observing the same infinite sequence of signals. (2) Moreover, before observing the signals, they believe with probability 1 that their posteriors about the underlying parameter will fail to converge. (3) Observing the same sequence of signals may lead to a divergence of opinion rather than the typically-presumed convergence. (4) Asymptotic disagreement (and lack of learning) may prevail even under approximate certainty-i.e., as we look at the limit where uncertainty about the interpretation of signals disappears. In particular, when the family of probability distributions of signals given the parameter have "regularly-varying tails" (such as the Pareto, the log-normal, and the t-distributions), approximate certainty is not sufficient to restore asymptotic learning and asymptotic agreement between agents with different priors. Lack of common beliefs and common priors has important implications for economic behavior in a range of circumstances. We illustrate how the type of learning outlined in this paper interacts with economic behavior in various different situations, including games of common interest, coordination, asset trading and bargaining.},
   author = {Daron Acemoglu and Victor Chernozhukov and Muhamet Yildiz},
   keywords = {Bayesian learning,C72,D83 1,asymptotic disagreement,merging of opinions JEL Classification: C11},
   title = {Learning and Disagreement in an Uncertain World},
   year = {2006},
}
@article{,
   abstract = {Different agents need to make a prediction. They observe identical data, but have different models: they predict using different explanatory variables. We study which agent believes they have the best predictive ability—as measured by the smallest subjective posterior mean squared prediction error—and show how it depends on the sample size. With small samples, we present results suggesting it is an agent using a low-dimensional model. With large samples, it is generally an agent with a high-dimensional model, possibly including irrelevant variables, but never excluding relevant ones. We apply our results to characterize the winning model in an auction of productive assets, to argue that entrepreneurs and investors with simple models will be overrepresented in new sectors, and to understand the proliferation of “factors” that explain the cross-sectional variation of expected stock returns in the asset-pricing literature.},
   author = {José Luis Montiel Olea and Pietro Ortoleva and Mallesh M Pai and Andrea Prat},
   doi = {10.1093/qje/qjac015},
   issn = {0033-5533},
   issue = {4},
   journal = {The Quarterly Journal of Economics},
   month = {9},
   pages = {2419-2457},
   publisher = {Oxford University Press (OUP)},
   title = {Competing Models},
   volume = {137},
   year = {2022},
}
@article{Heidhues2021,
   abstract = {We establish convergence of beliefs and actions in a class of one‐dimensional learning settings in which the agent's model is misspecified, she chooses actions endogenously, and the actions affect how she misinterprets information. Our stochastic‐approximation‐based methods rely on two crucial features: that the state and action spaces are continuous, and that the agent's posterior admits a one‐dimensional summary statistic. Through a basic model with a normal–normal updating structure and a generalization in which the agent's misinterpretation of information can depend on her current beliefs in a flexible way, we show that these features are compatible with a number of specifications of how exactly the agent updates. Applications of our framework include learning by a person who has an incorrect model of a technology she uses or is overconfident about herself, learning by a representative agent who may misunderstand macroeconomic outcomes, and learning by a firm that has an incorrect parametric model of demand.},
   author = {Paul Heidhues and Botond Koszegi and Philipp Strack},
   doi = {10.3982/te3558},
   issn = {1933-6837},
   issue = {1},
   journal = {Theoretical Economics},
   pages = {73-99},
   publisher = {The Econometric Society},
   title = {Convergence in models of misspecified learning},
   volume = {16},
   year = {2021},
}
