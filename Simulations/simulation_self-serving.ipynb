{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89782e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81aaac",
   "metadata": {},
   "source": [
    "# Generalized Bayes Update\n",
    "\n",
    "This is the bayes rule generalized to include self-serving beliefs. \n",
    "A self-serving belief will update asymmetrically when the evidence is positive or negative. When the evidence is positive, it will overweight the likelihood that it was generated by a pair of parameters such that $\\theta > \\omega$ and underweight the likelihood that it was generated by a pair of parameters such that $\\theta < \\omega$. When the evidence is negative, it will overweight the likelihood that it was generated by a pair of parameters such that $\\theta < \\omega$ and underweight the likelihood that it was generated by a pair of parameters such that $\\theta > \\omega$. This is done by adding parameters $c(\\theta, \\omega, news)$ such that\n",
    "\n",
    "<make a function defined by cases>\n",
    "\n",
    "$$ c(\\theta, \\omega, news) = \\begin{cases} \n",
    "      c_g^\\theta & \\text{ when } & \\theta > \\omega & \\text{ and } & news=g\\\\\n",
    "      c_b^\\theta & \\text{ when } & \\theta > \\omega & \\text{ and } & news=b\\\\\n",
    "      c_g^\\omega & \\text{ when } & \\theta < \\omega & \\text{ and } & news=g\\\\\n",
    "      c_g^\\omega & \\text{ when } & \\theta < \\omega & \\text{ and } & news=b\\\\\n",
    "      c = 1 & \\text{ otherwise   }\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "and with $c_g^\\theta>c_g^\\omega$ and $c_b^\\theta<c_b^\\omega $\n",
    "\n",
    "I take the bias to be symmetric for good news and bad news so that $c_g^\\theta=c_b^\\omega$ and $c_g^\\omega=c_b^\\theta$. In addition, I assume that it takes the values reported in Benjamin (2019). Which imply underreaction to both good and bad news: $c_g^\\theta=.27$ and $c_b^\\theta=.17$.\n",
    "\n",
    "I will consider news to be good whenever more than half of the evidence is positive and bad whenever more than half of the evidence is negative.\n",
    "\n",
    "The generalized bayes update rule is then given by:\n",
    "\n",
    "$$ p_t(\\theta, \\omega) = \\frac{p(s_t|\\theta, \\omega)^{c(\\theta, \\omega, news)}p_{t-1}(\\theta, \\omega)}{\\sum_{\\theta'}\\sum_{\\omega'}p(s_t|\\theta', \\omega')^{c(\\theta', \\omega', news)}p_{t-1}(\\theta', \\omega')} $$\n",
    "\n",
    "where $news$ is good if $s/trials$ is greater than 0.5 and bad otherwise.\n",
    "\n",
    "If $c$ is set to be constant ans equal to 1 for all possible values, then we get the standard bayes rule.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc5199",
   "metadata": {},
   "source": [
    "# The Data Generating Process\n",
    "\n",
    "There are 3 values of $\\theta$ and 3 values of $\\omega$. The probability of success is increasing in $\\theta$ and $\\omega$ and is maximized by choosing $e=\\omega$.\n",
    "\n",
    "The following table summarizes the DGP:\n",
    "\n",
    "|               | $\\omega_L$ | $\\omega_M$ | $\\omega_H$ |               | $\\omega_L$ | $\\omega_M$ | $\\omega_H$ |               | $\\omega_L$ | $\\omega_M$ | $\\omega_H$ |\n",
    "|:-------------:|:----------:|:----------:|:----------:|:-------------:|:----------:|:----------:|:----------:|:-------------:|:----------:|:----------:|:----------:|\n",
    "|     $e_H$     |     20     |     25     |     40      |     $e_H$     |     40     |     45     |    65      |     $e_H$     |     45     |     55     |     75     |\n",
    "|     $e_M$     |     7      |     30     |     45      |     $e_M$     |     30     |     65     |     69     |     $e_M$     |     35     |     69     |     80     |\n",
    "|     $e_L$     |     2      |     20     |     50      |     $e_L$     |      5     |     50     |     80     |     $e_L$     |     25     |     65     |     98     |\n",
    "|               |            | $\\theta_L$ |            |               |            | $\\theta_M$ |            |               |            | $\\theta_H$ |            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "afd76742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "seeds = [3452, 3452, 3452]\n",
    "\n",
    "# number of periods\n",
    "T = 10\n",
    "\n",
    "# number of trials\n",
    "be_trials = 10\n",
    "\n",
    "# alpha threshold for the switcher \n",
    "# (this will be estimated bu maximum likelihood from the data on the tables they are choosing to see)\n",
    "a = 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "f331baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 1, 2]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(3452\n",
    "           )\n",
    "        # draw the exogenous parameter for each task. It is 0, 1 or 2.\n",
    "        # These are the same for all players and are saved at the session level\n",
    "        # we want them to stay the same across sessions as well which is why a seed was set in advance\n",
    "a = random.randint(0, 2)\n",
    "b = random.randint(0, 2)\n",
    "c = random.randint(0, 2)\n",
    "d = random.randint(0, 2)\n",
    "e = random.randint(0, 2)\n",
    "f = random.randint(0, 2)\n",
    "\n",
    "[a, b, c, d, e, f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "851eb0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dgp\n",
    "# matrices: matrix[0] is the low type, matrix[2] is the high type. column 0 is low omega, row 0 is low effort\n",
    "ml = np.array([[.20, .25, .40], [.07, .30, .45], [.02, .20, .50]])\n",
    "mm = np.array([[.40, .45, .65], [.30, .65, .69], [.05, .50, .80]])\n",
    "mh = np.array([[.45, .55, .75], [.35, .69, .80], [.25, .65, .98]])\n",
    "\n",
    "msc = [ml, mm, mh]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "9366db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### THIS IS THE BAYES UPDATE WITH THE BIAS PARAMETERS C######\n",
    "# joint bayesian update\n",
    "\n",
    "def joint_bayes_biased(p0, signal, M, e_index, c):\n",
    "    # number of sucesses\n",
    "    k = sum(signal)\n",
    "    n = len(signal)\n",
    "    # determine if it is good news or bad news and set the parameter c accordingly\n",
    "    if k>=n/2:\n",
    "        c_theta = c[0]\n",
    "        c_omega = c[2]\n",
    "    else:\n",
    "        c_theta = c[1]\n",
    "        c_omega = c[3]\n",
    "    \n",
    "    # the probabilities of having observed each of the signals\n",
    "    matrix = np.array([sp.stats.binom.pmf(k, n, M[0][e_index, :], loc=0), \n",
    "                       sp.stats.binom.pmf(k, n, M[1][e_index, :], loc=0), \n",
    "                       sp.stats.binom.pmf(k, n, M[2][e_index, :], loc=0)])\n",
    "    \n",
    "    matrix_bias = [[matrix[0, 0], matrix[0, 1]**c_omega, matrix[0, 2]**c_omega],\n",
    "                     [matrix[1, 0]**c_theta, matrix[1, 1], matrix[1, 2]**c_omega],\n",
    "                        [matrix[2, 0]**c_theta, matrix[2, 1]**c_theta, matrix[2, 2]]]\n",
    "    \n",
    "    # set the numerators\n",
    "    num = np.diagflat(p0) @ np.diagflat(matrix_bias)\n",
    "    #take only the diagonal\n",
    "    num = np.diag(num)\n",
    "\n",
    "    # sum all the numerators to get the denominator\n",
    "    denom = np.sum(num)\n",
    "\n",
    "    # the posterior beliefs are each of the numerators divided by the denominator\n",
    "    p1 = num/denom\n",
    "\n",
    "    # p1 has the order (00, 01, 02, 10, 11, 12, 20, 21, 22)\n",
    "    \n",
    "    return p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "8b9ef36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian choices (the inputs are the belief (nine-dimensional array) and the DGP (msc), returns the index of the choice that maximizes the expected utility)\n",
    "# this can be used for the unbiased and the biased updates since it only takes the posterior belief ans calculates the expectated utility for each of the choices\n",
    "\n",
    "def joint_bayes_c(p1, M):\n",
    "    # compute the expected payoffs for each of the 3 choices\n",
    "    # the expected payoff is the probability of success times the probability of that combination of parameters\n",
    "    # Take the first row of each of the matrices in M and cancatenate them (this will match the order of the probabilities in the posterior)\n",
    "    choices_1 = np.concatenate((M[0][0, :], M[1][0, :], M[2][0, :]))\n",
    "    # Take the second row of each of the matrices in M and stack them\n",
    "    choices_2 = np.concatenate((M[0][1, :], M[1][1, :], M[2][1, :]))\n",
    "    # Take the third row of each of the matrices in M and concatenate them\n",
    "    choices_3 = np.concatenate((M[0][2, :], M[1][2, :], M[2][2, :]))\n",
    "\n",
    "    # multiply the choices by the probabilities in the posterior\n",
    "    Eu= [choices_1@p1, choices_2@p1, choices_3@p1]\n",
    "\n",
    "    e_index = np.argmax(Eu)\n",
    "    \n",
    "    return e_index\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "9a5c6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that simulates the joint biased bayes only (this can be turned into the correct bayesian y settinc c=[1, 1, 1, 1])\n",
    "\n",
    "def simulate_joint_bayes_biased(theta, omega, p0_theta, p0_omega, M, c, T, trials, seeds):\n",
    "    \n",
    "    ###### Determine the outcomes beforehand\n",
    "    # set a seed for each type\n",
    "    rng_H = np.random.default_rng(seed=seeds[0])\n",
    "    \n",
    "    \n",
    "\n",
    "    #############\n",
    "    # generate all the draws for T periods for each type and for each effort choice\n",
    "    ############\n",
    "\n",
    "    ##### for the high types\n",
    "    # outcomes after choosing L\n",
    "    outcome_H_L = rng_H.binomial(1, M[2][0, omega], size=(T, trials))\n",
    "    # outcomes after choosing M\n",
    "    outcome_H_M = rng_H.binomial(1, M[2][1, omega], size=(T, trials))\n",
    "    # outcomes after choosing H\n",
    "    outcome_H_H = rng_H.binomial(1, M[2][2, omega], size=(T, trials))\n",
    "\n",
    "    ##### for the medium types\n",
    "    rng_M = np.random.default_rng(seed=seeds[1])\n",
    "    # after low effort\n",
    "    outcome_M_L = rng_M.binomial(1, M[1][0, omega], size=(T, trials))\n",
    "    # after medium effort\n",
    "    outcome_M_M = rng_M.binomial(1, M[1][1, omega], size=(T, trials))\n",
    "    # after high effort\n",
    "    outcome_M_H = rng_M.binomial(1, M[1][2, omega], size=(T, trials))\n",
    "\n",
    "    #### for the low types\n",
    "    rng_L = np.random.default_rng(seed=seeds[2])\n",
    "    outcomes_L_L = rng_L.binomial(1, M[0][0, omega], size=(T, trials))\n",
    "    outcomes_L_M = rng_L.binomial(1, M[0][1, omega], size=(T, trials))\n",
    "    outcomes_L_H = rng_L.binomial(1, M[0][2, omega], size=(T, trials))\n",
    "\n",
    "    # stack the outcome vectors foe each type into a matrix. first element is the effort choice, secod is t\n",
    "    outcomes_H = np.stack((outcome_H_L, outcome_H_M, outcome_H_H))\n",
    "    outcomes_M = np.stack((outcome_M_L, outcome_M_M, outcome_M_H))\n",
    "    outcomes_L = np.stack((outcomes_L_L, outcomes_L_M, outcomes_L_H))\n",
    "\n",
    "    # stack all the matrices into a single outcomes matrix of matrices\n",
    "    outcomes = np.stack((outcomes_L, outcomes_M, outcomes_H))\n",
    "    \n",
    "    \n",
    "    #############\n",
    "    # set empty vectors where all the data will be saved period by period for each of the models\n",
    "    ############\n",
    "    # beliefs\n",
    "    # take every value of p0_theta and multiply by each value of p0_omega\n",
    "    p_joint_bayes_biased = [np.kron(p0_theta, p0_omega)]\n",
    "    \n",
    "    # choices\n",
    "    e_joint_bay_biased = [joint_bayes_c(p_joint_bayes_biased[0], M)]\n",
    "    \n",
    "    signals = outcomes[theta]\n",
    "    \n",
    "    for t in range(T):\n",
    "        # get the signals \n",
    "        \n",
    "        signal_bay = signals[e_joint_bay_biased[t], omega]\n",
    "        \n",
    "        # update beliefs \n",
    "        \n",
    "        p1_joint = joint_bayes_biased(p_joint_bayes_biased[t], signal_bay, M, e_joint_bay_biased[t], c)\n",
    "        p_joint_bayes_biased.append(p1_joint)\n",
    "    \n",
    "        \n",
    "        # Choices for each model and each believed type\n",
    "        e_joint_biased_t = joint_bayes_c(p_joint_bayes_biased[t], M)\n",
    "        e_joint_bay_biased.append(e_joint_biased_t)\n",
    "        \n",
    "    return e_joint_bay_biased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "bd381796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_joint_bayes_biased(0, 2, [1/3, 1/3, 1/3], [1/3, 1/3, 1/3], msc, attributions, 1, T, 1, be_trials, seeds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dac8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the priors on theta that an agent can have in the following order:\n",
    "# uniform, \n",
    "# 50% chance belief on 0, 75% chance belief on 0, 100% chance belief on 0,\n",
    "# 50% chance belief on 1, 75% chance belief on 1, 100% chance belief on 1,\n",
    "# 50% chance belief on 2, 75% chance belief on 2, 100% chance belief on 2.\n",
    "\n",
    "\n",
    "priors_theta = [[1/3, 1/3, 1/3], \n",
    "                [1/2, 1/4, 1/4],\n",
    "                [3/4, 1/8, 1/8],\n",
    "                [1, 0, 0],\n",
    "                [1/4, 1/2, 1/4],\n",
    "                [1/8, 3/4, 1/8],\n",
    "                [0, 1, 0],\n",
    "                [1/4, 1/4, 1/2],\n",
    "                [1/8, 1/8, 3/4],\n",
    "                [0, 0, 1]]\n",
    "\n",
    "\n",
    "# the prior on omega is induced and uniform\n",
    "prior_omega = [1/3, 1/3, 1/3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dc82ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the priors, simulate the choices under each of the parameterizations of the bias from attributions\n",
    "# where the attribution is [c_positive, c_negative, c_negative, c_positive] for each of the possible \n",
    "# combinations of c_positive and c_negative\n",
    "\n",
    "# create a matrix of the possible combinations of c_positive and c_negative\n",
    "c_positive = np.array([x for x in range(1, 20, 1)])/10\n",
    "c_negative = np.array([x for x in range(1, 20, 1)])/10\n",
    "\n",
    "grid_positive_negative = np.array(np.meshgrid(c_positive, c_negative)).T.reshape(-1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
